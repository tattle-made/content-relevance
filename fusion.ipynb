{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from io import BytesIO\n",
    "import captum\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import NoiseTunnel\n",
    "from torchsummary import summary\n",
    "import wget\n",
    "import sqlite3, json, io\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from pprint import pprint\n",
    "import json\n",
    "import math\n",
    "from math import sqrt\n",
    "import torch\n",
    "import itertools \n",
    "import torchtext\n",
    "from torchtext.data import Field, Dataset, Example\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from google.cloud import vision\n",
    "import sys,os,json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import vision\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "import requests\n",
    "import logging\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "from io import BytesIO\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget.download(\"https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.hi.align.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images and image text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations=transforms.Compose([\n",
    "                    transforms.Resize((224,224)), \n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, txt_path, img_dir, \n",
    "                 transform):\n",
    "        df = pd.read_csv(txt_path, sep=\" \", header=None, names= [\"img_name\"])\n",
    "        df[\"label\"] = df[\"img_name\"].apply(lambda x: 0 if \"neg\" in x else 1)\n",
    "        self.img_dir=img_dir\n",
    "        self.txt_path=txt_path\n",
    "        self.img_names=df[\"img_name\"].values\n",
    "        self.y = df[\"label\"].values\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.img_dir, self.img_names[idx])).convert('RGB')\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        img_text = self.get_image_text(os.path.join(self.img_dir, self.img_names[idx]), client)\n",
    "        if self.transform is not None:\n",
    "            img_vector=self.transform(img)\n",
    "        \n",
    "        label = self.y[idx]\n",
    "        return img_vector,label,img_text\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "    def get_image_text(self, path, client):  \n",
    "        def detect_text(img_bytes, client):\n",
    "            image_data = vision.types.Image(content=img_bytes)\n",
    "            resp = client.text_detection(image=image_data)\n",
    "            resp = json.loads(MessageToJson(resp))\n",
    "            text = resp.get('fullTextAnnotation',{}).get(\"text\",\"\")\n",
    "            return text\n",
    "        \n",
    "        image = Image.open(path, mode=\"r\")\n",
    "        imgByteArr = io.BytesIO()\n",
    "        image.save(imgByteArr, format=\"PNG\")\n",
    "        img_bytes = imgByteArr.getvalue()\n",
    "        text = detect_text(img_bytes, client)\n",
    "        return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomDataset(txt_path=\"/Users/kruttikanadig/Documents/Tattle/machine-learning/textfile.txt\",\n",
    "#                        img_dir=\"/Users/kruttikanadig/Documents/Tattle/machine-learning/all\",\n",
    "#                        transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(txt_path=\"/Users/kruttikanadig/Documents/Tattle/machine-learning/temp.txt\",\n",
    "                       img_dir=\"/Users/kruttikanadig/Documents/Tattle/machine-learning/few\",\n",
    "                       transform=transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create text preprocessing pipeline\n",
    "\n",
    "1. Tokenize training data and get word counts\n",
    "2. Load aligned word embeddings into aligned dict \n",
    "2. Create vocab and vocab2index using aligned dict and word counts\n",
    "3. Encode training data using vocab and vocab2index \n",
    "4. Apply to validation / test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(dataloader, inference=False, path=None, vocab2index=None):\n",
    "    \"\"\" Encodes text into sequences of vocabulary indices \"\"\"\n",
    "    \n",
    "    def tokenize(text):\n",
    "        \"\"\" Removes punctuation and numbers, converts to lowercase and splits into individual words \"\"\"\n",
    "        regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n\\ред]') # last character ред is the Hindi full stop\n",
    "        nopunct = regex.sub(\" \", text.lower())\n",
    "        tokenized_text = [token for token in nopunct.split(\" \") if len(token) > 0]\n",
    "        return tokenized_text\n",
    "    \n",
    "    def count_words(tokens, counts):\n",
    "        \"\"\" Counts unique words in text \"\"\"\n",
    "        counts.update(list(chain.from_iterable(tokens)))\n",
    "        return counts\n",
    "    \n",
    "    def load_embeddings(path):\n",
    "        \"\"\" Loads pretrained aligned word embeddings \"\"\"\n",
    "        words = []\n",
    "        idx = 0\n",
    "        word2idx = {}\n",
    "        vectors = []\n",
    "        fin = io.open(path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "        n, d = map(int, fin.readline().split())\n",
    "        for line in tqdm.tqdm(fin,total=n):\n",
    "            tokens = line.rstrip().split(' ')\n",
    "            vec = (list(map(float, tokens[1:])))\n",
    "            word = tokens[0].replace(\"'\",'\"')\n",
    "            words.append(word)\n",
    "            word2idx[word]=idx\n",
    "            vectors.append(vec)\n",
    "            idx+=1\n",
    "\n",
    "        vectors = np.array(vectors)\n",
    "        aligned_dict = {w: vectors[word2idx[w]] for w in words}\n",
    "        return aligned_dict\n",
    "    \n",
    "    def get_emb_matrix(pretrained, word_counts, emb_size = 300):\n",
    "        \"\"\" Creates training vocabulary, vocab2index and embedding matrix from pretrained word vectors \"\"\"\n",
    "        found=0\n",
    "        not_found=0\n",
    "        vocab_size = len(word_counts) + 2\n",
    "        vocab_to_idx = {}\n",
    "        vocab = [\"\", \"UNK\"]\n",
    "        W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "        W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "        W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "        vocab_to_idx[\"UNK\"] = 1\n",
    "        i = 2\n",
    "        for word in word_counts:\n",
    "            if word in pretrained:\n",
    "                W[i] = pretrained[word]\n",
    "                found+=1\n",
    "            else:\n",
    "                W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "                not_found+=1\n",
    "            vocab_to_idx[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1   \n",
    "        return W, np.array(vocab), vocab_to_idx, found, not_found\n",
    "    \n",
    "    def encode_tokens(tokenized_text, vocab2index, N=50): # keep max doc length to 50 words\n",
    "        \"\"\" Encodes tokenized text into equal length sequences of vocabulary indices \"\"\" \n",
    "        sequences = []\n",
    "        for text in tokenized_text:\n",
    "            seq = np.zeros(N, dtype=int)\n",
    "            # get word index if it's in vocab else get default index\n",
    "            enc = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in text])\n",
    "            # limit sequence length\n",
    "            length = min(N, len(enc))\n",
    "            seq[:length] = enc[:length]\n",
    "            sequences.append(seq)\n",
    "        return sequences\n",
    "\n",
    "    if inference==False:\n",
    "        counts = Counter()\n",
    "        tokenized_text = []\n",
    "        print(\"Tokenizing text and counting unique words\")\n",
    "        for i in dataloader:\n",
    "            tokenized = [tokenize(doc) for doc in i[2]]\n",
    "            counts = count_words(tokenized, counts)\n",
    "            tokenized_text.extend(tokenized)\n",
    "\n",
    "        print(\"Loading pretrained aligned word embeddings\")\n",
    "        aligned_dict = load_embeddings(path)\n",
    "\n",
    "        print(\"Creating vocab2index and embedding matrix with pretrained weights\")\n",
    "        pretrained_weights, vocab, vocab2index, found, not_found = get_emb_matrix(aligned_dict, counts)\n",
    "        sequences = encode_tokens(tokenized_text, vocab2index)\n",
    "        vocab_size = len(vocab)\n",
    "        print(\"Finished preparing sequences\")\n",
    "        return sequences, vocab, vocab_size, vocab2index, pretrained_weights\n",
    "    else:\n",
    "        print(\"Tokenizing text\")\n",
    "        tokenized_text = []\n",
    "        for i in dataloader:\n",
    "            tokenized = [tokenize(doc) for doc in i[2]]\n",
    "            tokenized_text.extend(tokenized)\n",
    "        sequences = encode_tokens(tokenized_text, vocab2index)\n",
    "        print(\"Finished preparing sequences\")\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and randomly split dataset into 80:20 training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-2.0323, -2.0323, -2.0323,  ..., -2.0152, -2.0152, -2.0323],\n",
      "         [-2.0323, -2.0323, -2.0323,  ..., -1.9467, -1.9638, -2.0323],\n",
      "         [-2.0323, -2.0323, -2.0323,  ..., -1.9124, -1.9124, -1.9980],\n",
      "         ...,\n",
      "         [-1.5870, -1.5870, -1.5870,  ..., -1.3644, -1.3473, -1.3473],\n",
      "         [-1.5699, -1.5699, -1.5699,  ..., -1.3644, -1.3644, -1.3815],\n",
      "         [-1.5357, -1.5357, -1.5357,  ..., -1.3644, -1.3815, -1.4158]],\n",
      "\n",
      "        [[-0.6877, -0.6877, -0.6877,  ..., -0.7052, -0.6877, -0.6702],\n",
      "         [-0.6877, -0.6877, -0.6877,  ..., -0.6702, -0.6702, -0.6702],\n",
      "         [-0.6877, -0.6877, -0.6877,  ..., -0.7227, -0.6527, -0.6352],\n",
      "         ...,\n",
      "         [-0.7402, -0.7402, -0.7402,  ..., -0.3550, -0.3375, -0.3375],\n",
      "         [-0.7227, -0.7227, -0.7227,  ..., -0.3550, -0.3550, -0.3725],\n",
      "         [-0.6877, -0.6877, -0.6877,  ..., -0.3550, -0.3725, -0.4076]],\n",
      "\n",
      "        [[ 0.8274,  0.8274,  0.8274,  ...,  0.7054,  0.7228,  0.7576],\n",
      "         [ 0.8274,  0.8274,  0.8274,  ...,  0.6705,  0.6879,  0.7576],\n",
      "         [ 0.8274,  0.8274,  0.8274,  ...,  0.5659,  0.6531,  0.7925],\n",
      "         ...,\n",
      "         [ 0.2696,  0.2696,  0.2696,  ...,  0.6879,  0.7054,  0.7054],\n",
      "         [ 0.2871,  0.2871,  0.2871,  ...,  0.6879,  0.6879,  0.6705],\n",
      "         [ 0.3219,  0.3219,  0.3219,  ...,  0.6879,  0.6705,  0.6356]]]), 0, '')\n",
      "(tensor([[[-0.8164, -0.8164, -0.7137,  ...,  2.2318,  2.2318,  2.2318],\n",
      "         [-0.7822, -0.7479, -0.6452,  ...,  2.2318,  2.2318,  2.2318],\n",
      "         [-0.5082, -0.4568, -0.4911,  ...,  2.2147,  2.2318,  2.2147],\n",
      "         ...,\n",
      "         [ 0.1254,  0.3652,  0.4166,  ...,  0.1083, -0.0801, -0.1999],\n",
      "         [ 0.1939,  0.3652,  0.3994,  ...,  0.0227, -0.1486, -0.2171],\n",
      "         [ 0.2967,  0.3309,  0.2796,  ..., -0.0458, -0.2342, -0.2856]],\n",
      "\n",
      "        [[-0.0924, -0.1450, -0.1275,  ...,  2.4286,  2.4286,  2.4286],\n",
      "         [-0.1275, -0.1275, -0.0574,  ...,  2.4286,  2.4286,  2.4286],\n",
      "         [ 0.0301,  0.1001,  0.1001,  ...,  2.4111,  2.4111,  2.4111],\n",
      "         ...,\n",
      "         [ 0.4503,  0.6779,  0.6954,  ...,  0.8880,  0.7829,  0.7304],\n",
      "         [ 0.2402,  0.4153,  0.4678,  ...,  0.8354,  0.7304,  0.7304],\n",
      "         [ 0.1176,  0.2052,  0.2402,  ...,  0.7654,  0.6429,  0.6429]],\n",
      "\n",
      "        [[-1.4036, -1.4210, -1.3687,  ...,  2.5529,  2.5529,  2.5529],\n",
      "         [-1.4559, -1.4384, -1.3513,  ...,  2.5529,  2.5529,  2.5529],\n",
      "         [-1.3339, -1.2641, -1.2641,  ...,  2.5354,  2.5529,  2.5354],\n",
      "         ...,\n",
      "         [-0.1487,  0.0953,  0.1825,  ...,  0.0256,  0.0431,  0.0431],\n",
      "         [-0.2707, -0.0615,  0.0256,  ..., -0.1835, -0.0964, -0.0092],\n",
      "         [-0.3230, -0.2184, -0.1661,  ..., -0.3578, -0.2358, -0.1138]]]), 0, 'OA Shot on OnePlus\\nBy Ankesh\\n')\n",
      "(tensor([[[-0.6965, -0.6965, -0.6965,  ..., -1.3644, -1.4158, -1.3644],\n",
      "         [-0.6965, -0.6965, -0.6965,  ..., -1.2274, -1.3815, -1.4329],\n",
      "         [-0.6965, -0.6965, -0.6965,  ..., -1.0904, -1.3130, -1.4843],\n",
      "         ...,\n",
      "         [ 1.3927,  1.3927,  1.3927,  ...,  1.3927,  1.3927,  1.3927],\n",
      "         [ 1.3755,  1.3755,  1.3755,  ...,  1.3755,  1.3755,  1.3755],\n",
      "         [ 1.4098,  1.4098,  1.4098,  ...,  1.4098,  1.4098,  1.4098]],\n",
      "\n",
      "        [[ 0.9930,  0.9930,  0.9930,  ..., -0.3901, -0.4076, -0.3375],\n",
      "         [ 0.9930,  0.9930,  0.9930,  ..., -0.2500, -0.3725, -0.4076],\n",
      "         [ 0.9930,  0.9930,  0.9930,  ..., -0.0924, -0.3025, -0.4601],\n",
      "         ...,\n",
      "         [ 1.5532,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5532],\n",
      "         [ 1.5357,  1.5357,  1.5357,  ...,  1.5357,  1.5357,  1.5357],\n",
      "         [ 1.5707,  1.5707,  1.5707,  ...,  1.5707,  1.5707,  1.5707]],\n",
      "\n",
      "        [[ 2.3088,  2.3088,  2.3088,  ...,  1.0017,  0.8099,  0.7925],\n",
      "         [ 2.3088,  2.3088,  2.3088,  ...,  1.1411,  0.8448,  0.7054],\n",
      "         [ 2.3088,  2.3088,  2.3088,  ...,  1.2980,  0.9319,  0.6705],\n",
      "         ...,\n",
      "         [ 1.7685,  1.7685,  1.7685,  ...,  1.7685,  1.7685,  1.7685],\n",
      "         [ 1.7511,  1.7511,  1.7511,  ...,  1.7511,  1.7511,  1.7511],\n",
      "         [ 1.7860,  1.7860,  1.7860,  ...,  1.7860,  1.7860,  1.7860]]]), 0, 'рдкрдЯрдорд╛рддреНрдорд╛ рдХрд╛\\nрдирд╛рдо рдХрд░рдмреАрд░ рд╣реИред\\nрдкрд╡рд┐рддреНрд░ рдЕрдерд░реНрд╡рд╡реЗрдж рдХрд╛рдгреНрдб рдирдВ. 4 рдЕрдиреБрд╡рд╛рдХ рдирдВ. 1 рдордВрддреНрд░ 7\\nрдпреЛрдерд░реНрд╡рд╛рдгрдВ рдкрд┐рддреНрддрд░рдВ рджреЗрд╡рдмрдиреНрдзреБрдВ рдмрд╣рд╕реНрдкрддрд┐рдВ рдирдорд╕рд╛рд╡ рдЪ рдЧрдЪреНрдЫрд╛рддреН ред рддреНрд╡рдВ рд╡рд┐рд╢реНрд╡реЗрд╖рд╛рдВ рдЬрдирд┐рддрд╛\\nрдпрдерд╛рд╕рдГ рдХрд╡рд┐рджреЗрд╡реЛ рди рджрднрд╛рдпрддреН рд╕реНрд╡рдзрд╛рд╡рд╛рдиреНредред\\nрдкрд░рдореЗрд╢реНрд╡рд░ рдХрд╛ рдирд╛рдо рдХрд╡рд┐рд░реНрджреЗрд╡ рд╣реИ рдЬреЛ рдЕрд╡рд┐рдирд╛рд╢реА рдЬрдЧрддреН рдЧреБрд░реБ, рдЖрддреНрдорд╛рдзрд╛рд░,\\nрдкреВрд░реНрдг рдореБрдХреНрдд рд╣реЛрдХрд░ рд╕рддреНрдпрд▓реЛрдХ рдЧрдП рд╣реИрдВ рдЙрдирдХреЛ рд╕рддрд▓реЛрдХ рд▓реЗ рдЬрд╛рдиреЗ рд╡рд╛рд▓рд╛,\\nрдмреНрд░рд╣реНрдордгреНрдбреЛрдВ рдХрд╛ рд░рдЪрдирд╣рд╛рд░, рдХрд╛рд▓ рдХреА рддрд░рд╣ рдзреЛрдЦрд╛ рди рджреЗрдиреЗ рд╡рд╛рд▓рд╛ рдХрдмреАрд░ рдкреНрд░рднреБ рд╣реИред\\nрдЬреЛ\\nрд╕рд░реНрд╡\\nрдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП рдкрд╡рд┐рддреНрд░ рдкреБрд╕реНрддрдХ \"рдЬреНрдЮрд╛рди рдЧрдВрдЧрд╛\" рдирд┐:рд╢реБрд▓реНрдХ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВред рдЕрдкрдирд╛ рдирд╛рдо,\\nрдкреВрд░рд╛ рдкрддрд╛, рдореЛрдмрд╛рдЗрд▓ рдирдВрдмрд░ рд╣рдореЗрдВ Whatsapp рдХрд░реЗрдВ +91 7496801825\\nSPIRITUAL LEADER\\nSANT RAMPAL JI\\nfO in\\n@SAINTRAMPALJIM\\nSUPREMEGOD.ORG\\nSAINT RAMPAL JI\\nMAHARAJ\\n')\n"
     ]
    }
   ],
   "source": [
    "len(dataset)\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text and counting unique words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|тЦП         | 1979/158016 [00:00<00:15, 9922.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained aligned word embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 158016/158016 [00:19<00:00, 8131.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab2index and embedding matrix with pretrained weights\n",
      "Finished preparing sequences\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/kruttikanadig/Documents/Tattle/machine-learning/wiki.hi.align.vec\"\n",
    "train_sequences, vocab, vocab_size, vocab2index, pretrained_weights = prepare_sequences(train_loader, inference=False, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text\n",
      "Finished preparing sequences\n"
     ]
    }
   ],
   "source": [
    "valid_sequences = prepare_sequences(validation_loader, inference=True, vocab2index=vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_loader = torch.utils.data.DataLoader(train_sequences, batch_size=2, shuffle=False)\n",
    "valid_seq_loader = torch.utils.data.DataLoader(valid_sequences, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2147,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2147,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2147,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 1.3927,  1.3413,  1.3413,  ...,  1.3755,  1.3755,  1.3755],\n",
      "          [ 1.3584,  1.3584,  1.3584,  ...,  1.3584,  1.3584,  1.3584],\n",
      "          [ 1.3584,  1.3584,  1.3584,  ...,  1.3584,  1.3584,  1.3584]],\n",
      "\n",
      "         [[ 2.0959,  2.0959,  2.0959,  ...,  2.0609,  2.0959,  2.0959],\n",
      "          [ 2.0959,  2.0959,  2.0959,  ...,  2.0609,  2.0959,  2.0959],\n",
      "          [ 2.0959,  2.0959,  2.0959,  ...,  2.0609,  2.0959,  2.0959],\n",
      "          ...,\n",
      "          [ 1.5532,  1.5007,  1.5007,  ...,  1.5357,  1.5357,  1.5357],\n",
      "          [ 1.5182,  1.5182,  1.5182,  ...,  1.5182,  1.5182,  1.5182],\n",
      "          [ 1.5182,  1.5182,  1.5182,  ...,  1.5182,  1.5182,  1.5182]],\n",
      "\n",
      "         [[-0.7936, -0.7936, -0.7936,  ..., -0.8284, -0.7936, -0.7936],\n",
      "          [-0.7936, -0.7936, -0.7936,  ..., -0.8284, -0.7936, -0.7936],\n",
      "          [-0.7936, -0.7936, -0.7936,  ..., -0.8284, -0.7936, -0.7936],\n",
      "          ...,\n",
      "          [ 1.7685,  1.7163,  1.7163,  ...,  1.7511,  1.7511,  1.7511],\n",
      "          [ 1.7337,  1.7337,  1.7337,  ...,  1.7337,  1.7337,  1.7337],\n",
      "          [ 1.7337,  1.7337,  1.7337,  ...,  1.7337,  1.7337,  1.7337]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4612,  1.4612,  1.4612,  ...,  1.4612,  1.4612,  1.4612],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.4612,  1.4612,  1.4612,  ...,  1.4612,  1.4612,  1.4612]],\n",
      "\n",
      "         [[ 1.6232,  1.6232,  1.6232,  ...,  1.6232,  1.6232,  1.6232],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.6232,  1.6232,  1.6232,  ...,  1.6232,  1.6232,  1.6232]],\n",
      "\n",
      "         [[ 1.8383,  1.8383,  1.8383,  ...,  1.8383,  1.8383,  1.8383],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.8383,  1.8383,  1.8383,  ...,  1.8383,  1.8383,  1.8383]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5022,  0.5022,  0.5022,  ...,  0.5022,  0.5022,  0.5022],\n",
      "          [ 0.5022,  0.5022,  0.5022,  ...,  0.5022,  0.5022,  0.5022],\n",
      "          [ 0.5022,  0.5022,  0.5022,  ...,  0.5022,  0.5022,  0.5022],\n",
      "          ...,\n",
      "          [ 0.5022,  0.5022,  0.5022,  ...,  0.5022,  0.5022,  0.5022],\n",
      "          [ 0.5022,  0.5022,  0.5022,  ...,  0.5022,  0.5022,  0.5022],\n",
      "          [ 0.5022,  0.5022,  0.5022,  ...,  0.5022,  0.5022,  0.5022]],\n",
      "\n",
      "         [[ 0.0651,  0.0651,  0.0651,  ...,  0.0651,  0.0651,  0.0651],\n",
      "          [ 0.0651,  0.0651,  0.0651,  ...,  0.0651,  0.0651,  0.0651],\n",
      "          [ 0.0651,  0.0651,  0.0651,  ...,  0.0651,  0.0651,  0.0651],\n",
      "          ...,\n",
      "          [ 0.0651,  0.0651,  0.0651,  ...,  0.0651,  0.0651,  0.0651],\n",
      "          [ 0.0651,  0.0651,  0.0651,  ...,  0.0651,  0.0651,  0.0651],\n",
      "          [ 0.0651,  0.0651,  0.0651,  ...,  0.0651,  0.0651,  0.0651]],\n",
      "\n",
      "         [[-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          ...,\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247],\n",
      "          [-1.1247, -1.1247, -1.1247,  ..., -1.1247, -1.1247, -1.1247]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5082, -0.7479, -0.9192,  ..., -0.7308, -0.7137, -1.0048],\n",
      "          [-0.5596, -0.7137, -0.7650,  ..., -0.5767, -0.5767, -0.9192],\n",
      "          [-0.5424, -0.5938, -0.5767,  ..., -0.4911, -0.4911, -0.8335],\n",
      "          ...,\n",
      "          [-0.4739, -0.4739, -0.4911,  ..., -1.6384, -1.6042, -1.6555],\n",
      "          [-0.4911, -0.4911, -0.4911,  ..., -1.6898, -1.6384, -1.7240],\n",
      "          [-0.4911, -0.4911, -0.4911,  ..., -1.6727, -1.6555, -1.7412]],\n",
      "\n",
      "         [[-0.2850, -0.5301, -0.7052,  ..., -0.6527, -0.6352, -0.9328],\n",
      "          [-0.3375, -0.4951, -0.5476,  ..., -0.5651, -0.5651, -0.9153],\n",
      "          [-0.3200, -0.3725, -0.3550,  ..., -0.5826, -0.5826, -0.9153],\n",
      "          ...,\n",
      "          [-0.4251, -0.4251, -0.4426,  ..., -1.7556, -1.7206, -1.7731],\n",
      "          [-0.4426, -0.4426, -0.4426,  ..., -1.8081, -1.7556, -1.8256],\n",
      "          [-0.4426, -0.4426, -0.4426,  ..., -1.7906, -1.7731, -1.8431]],\n",
      "\n",
      "         [[ 0.2173, -0.0267, -0.2010,  ..., -0.4798, -0.4624, -0.7587],\n",
      "          [ 0.1651,  0.0082, -0.0441,  ..., -0.3753, -0.3753, -0.7238],\n",
      "          [ 0.1825,  0.1302,  0.1476,  ..., -0.3578, -0.3578, -0.6890],\n",
      "          ...,\n",
      "          [-0.2532, -0.2532, -0.2707,  ..., -1.5256, -1.4907, -1.5430],\n",
      "          [-0.2707, -0.2707, -0.2707,  ..., -1.5779, -1.5256, -1.5953],\n",
      "          [-0.2707, -0.2707, -0.2707,  ..., -1.5604, -1.5430, -1.6127]]],\n",
      "\n",
      "\n",
      "        [[[-1.1760, -1.1760, -1.1760,  ..., -0.8335, -0.8335, -0.8335],\n",
      "          [-1.1760, -1.1760, -1.1760,  ..., -0.8335, -0.8335, -0.8335],\n",
      "          [-1.1760, -1.1760, -1.1760,  ..., -0.8335, -0.8335, -0.8335],\n",
      "          ...,\n",
      "          [-1.5014, -1.5014, -1.5014,  ..., -1.1760, -1.1760, -1.1418],\n",
      "          [-1.5185, -1.5528, -1.5528,  ..., -1.2103, -1.1760, -1.1418],\n",
      "          [-1.5185, -1.5870, -1.5699,  ..., -1.2103, -1.1760, -1.1760]],\n",
      "\n",
      "         [[-0.7052, -0.7052, -0.7052,  ..., -0.5301, -0.5301, -0.5301],\n",
      "          [-0.7052, -0.7052, -0.7052,  ..., -0.5301, -0.5301, -0.5301],\n",
      "          [-0.7052, -0.7052, -0.7052,  ..., -0.5301, -0.5301, -0.5301],\n",
      "          ...,\n",
      "          [-1.4055, -1.4055, -1.4055,  ..., -1.2479, -1.2479, -1.2129],\n",
      "          [-1.4230, -1.4580, -1.4580,  ..., -1.2829, -1.2479, -1.2129],\n",
      "          [-1.4230, -1.4930, -1.4755,  ..., -1.2829, -1.2479, -1.2479]],\n",
      "\n",
      "         [[ 0.0256,  0.0256,  0.0256,  ...,  0.1825,  0.1825,  0.1825],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.1825,  0.1825,  0.1825],\n",
      "          [ 0.0256,  0.0256,  0.0256,  ...,  0.1825,  0.1825,  0.1825],\n",
      "          ...,\n",
      "          [-1.1770, -1.1770, -1.1770,  ..., -1.0550, -1.0550, -1.0201],\n",
      "          [-1.1944, -1.2293, -1.2293,  ..., -1.0898, -1.0550, -1.0201],\n",
      "          [-1.1944, -1.2641, -1.2467,  ..., -1.0898, -1.0550, -1.0550]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0948,  2.1119,  2.0948,  ...,  2.0948,  2.0948,  2.0948],\n",
      "          [ 2.0948,  2.0948,  1.9920,  ...,  2.0605,  2.0948,  2.0948],\n",
      "          [ 2.0948,  2.0777,  1.1700,  ...,  1.9749,  2.0777,  2.0948],\n",
      "          ...,\n",
      "          [ 2.1290,  2.0948,  2.0263,  ...,  1.9920,  2.0948,  2.0948],\n",
      "          [ 2.0948,  2.0948,  2.0777,  ...,  2.0777,  2.0948,  2.0948],\n",
      "          [ 2.0777,  2.0948,  2.0948,  ...,  2.1119,  2.0948,  2.0948]],\n",
      "\n",
      "         [[ 2.2710,  2.2885,  2.2710,  ...,  2.2710,  2.2710,  2.2710],\n",
      "          [ 2.2710,  2.2710,  2.1660,  ...,  2.2360,  2.2710,  2.2710],\n",
      "          [ 2.2710,  2.2535,  1.3256,  ...,  2.1485,  2.2535,  2.2710],\n",
      "          ...,\n",
      "          [ 2.2710,  2.2535,  2.1835,  ...,  2.1660,  2.2710,  2.2710],\n",
      "          [ 2.2885,  2.2710,  2.2535,  ...,  2.2535,  2.2710,  2.2710],\n",
      "          [ 2.2885,  2.2710,  2.2710,  ...,  2.2885,  2.2710,  2.2710]],\n",
      "\n",
      "         [[ 2.4831,  2.5006,  2.4831,  ...,  2.4831,  2.4831,  2.4831],\n",
      "          [ 2.4831,  2.4831,  2.3786,  ...,  2.4483,  2.4831,  2.4831],\n",
      "          [ 2.4831,  2.4657,  1.5420,  ...,  2.3611,  2.4657,  2.4831],\n",
      "          ...,\n",
      "          [ 2.4831,  2.4483,  2.3960,  ...,  2.3786,  2.4831,  2.4831],\n",
      "          [ 2.3786,  2.3960,  2.3960,  ...,  2.4657,  2.4831,  2.4831],\n",
      "          [ 2.4483,  2.4483,  2.4657,  ...,  2.5006,  2.4831,  2.4831]]]]), tensor([0, 1, 0, 1, 1, 1, 0, 0]), ('KABIR SAHEB A ALLAH HAIN\\nрдЖрдпрдд 52 :- рдлрд▓рд╛ рддреБрддрд┐рдЕрд▓реН - рдХрд╛рдлрд┐рд░рдиреН рд╡\\nрдЬрд╣рд┐рдврд╣реБрдо рдмрд┐рд╣реА рдЬрд┐рд╣рд╛рдврдиреН рдХрдмреАрд░рд╛рдХрдмреАрд░реН)\\nрд╣рдЬрд░рдд рдореБрд╣рдореНрдордж рдЬреА рдХреЛ рдЦреБрджрд╛ (рдкреНрд░рднреБ) рдХрд╣ рд░рд╣реЗ рд╣реИ рдХрд┐ рд╣реЗ рдкреИрдЧрдореНрдмрд░ ! рдЖрдк рдХрд╛рдлрд┐рд░реЛрдВ\\n(рдЬреЛ рдПрдХ рдкреНрд░рднреБ рдХреА рднрдХреНрддрд┐ рддреНрдпрд╛рдЧ рдХрд░ рдЕрдиреНрдп рджреЗрд╡реА-рджреЗрд╡рддрд╛рдУрдВ рддрдерд╛ рдореВрд░реНрддрд┐ рдЖрджрд┐\\nрдХреА рдкреВрдЬрд╛ рдХрд░рддреЗ рд╣реИрдВ) рдХрд╛ рдХрд╣рд╛ рдордд рдорд╛рдирдирд╛, рдХреНрдпреЛрдВрдХрд┐ рд╡реЗ рд▓реЛрдЧ рдХрдмреАрд░ рдХреЛ рдкреВрд░реНрдг\\nрдкрд░рдорд╛рддреНрдорд╛ рдирд╣реАрдВ рдорд╛рдирддреЗред рдЖрдк рдореЗрд░реЗ рджреНрд╡рд╛рд░рд╛ рджрд┐рдП рдЗрд╕ рдХреБрд░рд╛рди рдХреЗ рдЬреНрдЮрд╛рди рдХреЗ рдЖрдзрд╛рд░\\nрдкрд░ рдЕрдЯрд▓ рд░рд╣рдирд╛ рдХрд┐ рдХрдмреАрд░ рд╣реА рдкреВрд░реНрдг рдкреНрд░рднреБ рд╣реИ рддрдерд╛ рдХрдмреАрд░ рдЕрд▓реНрд▓рд╛рд╣ рдХреЗ рд▓рд┐рдП\\nрд╕рдВрдШрд░реНрд╖ рдХрд░рдирд╛ (рд▓рдбрд╝рдирд╛ рдирд╣реАрдВ) рдЕрд░реНрдерд╛рддреН рдЕрдбрд┐рдЧ рд░рд╣рдирд╛ред\\nFREE\\nGyan Gariga\\nрдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП\\nрдкрд╡рд┐рддреНрд░ рдкреБрд╕реНрддрдХ\"рдЬреНрдЮрд╛рди рдЧрдВрдЧрд╛ рдирд┐:рд╢реБрд▓реНрдХ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВред\\nрдЕрдкрдирд╛ рдирд╛рдо, рдкреВрд░рд╛ рдкрддрд╛, рдореЛрдмрд╛рдЗрд▓ рдирдВрдмрд░ рд╣рдореЗрдВ Whatsapp рдХрд░реЗрдВ -9496801825\\nE SUPREMEGOD.ORG\\nSANT RAMPAL JI\\nSPIRITUAL LEADER\\n@SAINTRAMPALJIM\\nin P\\nMAHARAJ\\nSAINT RAMPAL JI\\nFREE\\n', '4G. 4G\\nl 12:32\\nO Y, 40 92%\\n0.00\\nLTE1\\n+ Varun Jain\\nрдЖрд╡рд╢реНрдпрдХ рд╕реВрдЪрдирд╛:-\\nрдЕрднреА рдЕрднреА рдЬрд╛рдирдХрд╛рд░реА рдорд┐рд▓реА рд╣реИ рдХрд┐ рдЧреНрд░рд╛рдо рдирд╛рдЧреЗрд▓рд╛рд╡ рд╡рд╛рдпрд╛ рдкреАрд╕рд╛рдВрдЧрди рдЬрд┐рд▓рд╛ рдЕрдЬрдореЗрд░\\nрдореЗрдВ рдПрдХ рдмрд╛рд▓рд┐рдХрд╛ рдХрд╛ рдЬрдиреНрдо рд╣реЙрд╕реНрдкрд┐рдЯрд▓ рдореЗрдВ рд╣реБрдЖред рдмрд╛рд▓рд┐рдХрд╛ рдиреЗ рдЬрдиреНрдо рд▓реЗрддреЗ рд╣реА рдмреЛрд▓реА\\nрдХрд┐ рднрд╛рд░рдд рдореЗрдВ рдЬреЛ рдХреЛрд░реЛрдирд╛ рд╡рд╛рдпрд░рд╕ рд╕рдВрдХреНрд░рдордг рдлреИрд▓рд╛ рд╣реБрдЖ рд╣реИ рдЙрд╕рдХреЗ рдмрдЪрд╛рд╡ рдХреЗ рд▓рд┐рдП\\nрднрд╛рд░рдд рдХреЗ рдкреНрд░рддреНрдпреЗрдХ рдирд╛рдЧрд░рд┐рдХ рдХреЛ рдЕрдкрдиреЗ рджрд╛рдПрдВ рдкреИрд░ рдХреЗ рдЕрдВрдЧреВрдареЗ рдХреЗ рдирд╛рдЦреВрди рдкрд░ рд╣рд▓реНрджреА рдХрд╛\\nрд▓реЗрдк (рдореЗрд╣рдВрджреА рдХреА рддрд░рд╣) рд▓рдЧрд╛рдирд╛ рд╣реИред рдЗрд╕рд╕реЗ рдХреЛрд░реЛрдирд╛ рдХрд╛ рд╕рдВрдХреНрд░рдордг рд╕рдорд╛рдкреНрдд рд╣реЛ\\nрдЬрд╛рдПрдЧрд╛ рд╕рднреА рдирд╛рдЧрд░рд┐рдХ рд╕рдХреБрд╢рд▓ рд░рд╣реЗрдВрдЧреЗред рдпрд╣ рдХрд╣рдХрд░ рдмрд╛рд▓рд┐рдХрд╛ рдХреА рдЙрд╕реА рд╕рдордп\\nрдореГрддреНрдпреБ рд╣реЛ рдЧрдИ рдпрд╣ рджреЗрдЦрдХрд░ рдЕрд╕реНрдкрддрд╛рд▓ рдХреЗ рдбреЙрдХреНрдЯрд░ рднреА рдЖрд╢реНрдЪрд░реНрдпрдЪрдХрд┐рдд рд╣реЛ рдЧрдПред рдЕрддрдГ\\nрдЖрдкрд╕реЗ рдирд┐рд╡реЗрджрди рд╣реИ рдХрд┐ рдЖрдк рднреА рддрддреНрдХрд╛рд▓ рдЗрд╕ рддрд░рд╣ рдХрд╛ рд▓реЗрдк рдЕрдкрдиреЗ рджрд╛рдПрдВ рдкреИрд░ рдХреЗ\\nрдЕрдВрдЧреВрдареЗ рдХреЗ рдирд╛рдЦреВрди рдкрд░ рд▓рдЧрд╛рдХрд░ рдХреЛрд░реЛрдирд╛ рд╡рд╛рдпрд░рд╕ рд╕рдВрдХреНрд░рдордг рд╕реЗ рдЕрдкрдирд╛ рдПрд╡рдВ рдЕрдкрдиреЗ\\nрдкрд░рд┐рд╡рд╛рд░ рдХрд╛ рдЬреАрд╡рди рдХреЛ рдмрдЪрд╛рдПрдВред рдпрд╣ рдлреЗрдХ рдиреНрдпреВрдЬ рдирд╣реАрдВ рд╣реИ рд╕рддреНрдп рдШрдЯрдирд╛ рд╣реИред\\nрдкреБрд░реБрд╖ рд╢реМрдЪрд╛рд▓рдп\\nрдУ. рдкреА. рдбреА.\\nGENTS TOILET\\nO.P.D.\\nIMMUNIZATION\\nELECTRICAL ROOM\\nSTAIRGASE\\nD.D. W. STORE\\nрдЯреАрдХрд╛рдХрд░рдг рдХрдХреНрд╖\\nрд╡рд┐рджреНрдпреБрдд - рдХрдХреНрд╖\\nDрзз|рджрд╡рд╛ рднрдгреНрдбрд╛рд░\\nSTORE\\n-2 рдореБрд░реНрджрд╛ рдЪреАрд░-рдХрд╛рдб рдХрдХреНрд╖ POST MAP\\n| рд╕реНрд╡рд╛рд╕реНрдереНрдп рдХреЗрдиреНрджреНрд░-рдХрд╛рд▓рди\\nSince 19\\nLike\\nComment\\nShare\\nWrite a comment.\\n(GIF\\n', 'рдХреЛрд░реЛрдирд╛ рдмрдЪрд╛рдиреЗ рдХреЗ\\nрдкреБрд▓рд┐рд╕ рд╡рд╛рд▓реАрдВ рдХреЗ рдордВрддреНрд░\\nрдШрд░ рд╕реЗ рдмрд╛рд╣рд░ рди рдирд┐рдХрд▓реЗ\\nрдирд┐рдХрд▓реЗ рддреЛ рддреЛрдбрд╝ рджреЗрдВрдЧреЗ\\nрд╢рд░реАрд░ рдХрд╛ рдХреЛрдирд╛ рдХреЛрдирд╛\\nрдордЧрд░ рд╣реЛрдиреЗ рдирд╣реА рдж\\nрдХрд┐рд╕реА рдХреЛ рдХреЛрд░реЛрдирд╛ редред\\n', 'Corona рдорд╣рд╛рдорд╛рд░реА рдХреЛ рджреЗрдЦрддреЗ рд╣реБрдП\\nTiger Shroff рдиреЗ рд╕рд░рдХрд╛рд░ рдХреЛ рджреАрдпрд╛\\n350 рдХрд░реЛрдбрд╝ рдХрд╛ рдЪреЗрдХ\\n[CDS)\\nрд░реАрдпрд▓ рд╣реАрд░реЛ рд╣\\nTiger Shroff\\n', 'рдкрд░рд┐рд╖рдж\\nCANTONMERT BOARO\\nрд╕рддреНрдпрдореЗрдж рдЙрдпрддреЗ\\nрдХреЛрд░реЛрдирд╛ рд╡рд╛рдпрд░рд╕ рдПрд▓рд░реНрдЯ\\nрдЬрди рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╣рд┐рдд рдореЗрдВ рдЬрд╛рд░реА\\nрдмрдЪрд╛рд╡ рдПрд╡рдВ рдЙрдкрдЪрд╛рд░ -\\n1. рдЕрдкрдиреЗ рдШрд░ рдореЗрдВ рдХрд╣реАрдВ рднреА рдЖрд░реНрджреНрд░ рд╡рд╛рддрд╛рд╡рд░рдг рди рд╣реЛрдиреЗ рджреЗрдВред\\n2. рдХрдкрдбрд╝реЛрдВ рдХреЛ рддреЗрдЬ рдзреВрдк рдореЗрдВ рд╕реБрдЦрд╛рдпреЗрдВред\\n3. рдиреАрдмреВ рдХреЗ рдкрддрд▓реЗ рдЯреБрдХрдбрд╝реЗ рдЧреБрдирдЧреБрдиреЗ рдкрд╛рдиреА рдХреЗ рд╕рд╛рде рджрд┐рдирднрд░ рдкреАрддреЗ рд░рд╣реЗрдВред рдиреАрджреВ рдореЗрдВ рдЙрдкрд╕реНрдерд┐рдд рд╡рд┐рдЯрд╛рдорд┐рди\\nрд╕реА рдЖрдкрдХреА рдкреНрд░рддрд┐рд░рдХреНрд╖рд╛ рд╢рдХреНрддрд┐ рдмрдврд╝рд╛рддрд╛ рд╣реИред рд╡рд┐рдЯрд╛рдорд┐рди рд╕реА рдШреБрд▓рдирд╢реАрд▓ рд╣реЛрдиреЗ рдХреА рд╡рдЬрд╣ рд╕реЗ\\nрджрд┐рдирднрд░рдЗрд╕рдХрд╛ рд╕реЗрд╡рди рдХрд░рдирд╛ рд▓рд╛рднрджрд╛рдпрдХ рд╣реЛрдЧрд╛ред\\n4. рдХрдЪреНрдЪреЗ рд╕рд▓рд╛рдж (рдЬреИрд╕реЗ-рдореВрд▓реА, рдЧрд╛рдЬрд░, рдЯрдорд╛рдЯрд░ рдЗрддреНрдпрд╛рджрд┐) рди рдЦрд╛рдпреЗрдВ ред\\n5. рдЬреЛ рднреА рдЦрд╛рдпреЗрдВ рднрд░рдкреВрд░ рдкрдХрд╛ рдХрд░ рдЦрд╛рдпреЗрдВред рдлрд▓ рд╕рд┐рд░реНрдл рд╡рд╣реАрдВ рдЦрдпреЗрдВ рдЬрд┐рд╕рдХреЗ рдкреВрд░реЗ рдЫрд┐рд▓рдХреЗ рдЙрддрд░ рдЬрд╛рддреЗ\\nрд╣реИрдВред рдЬреИрд╕реЗ-рдХреЗрд▓рд╛, рд╕рдиреНрддрд░рд╛ред\\n6. рдЕрдкрдиреЗ рд╣рд╛рдереЛрдВ рдХреЛ рд╕рд╛рдмреБрди/рдПрд▓реНрдХреЛрд╣рд▓рдпреБрдХреНрдд рд╕реЗрдиреЗрдЯрд╛рдЗрдЬрд░ рд╕реЗ рд▓рдЧрд╛рддрд╛рд░ рдзреЛрддреЗ рд░рд╣реЗрдВред рд╣рд╛рде рд╕реЗ рдЪреЗрд╣рд░реЗ\\nрдХреЛрдирдЫреБрд╡реЗрдВред рдЬрдм рднреА рдЦрд╛рдБрд╕реЗ рдпрд╛ рдЫрд┐рдХреНрдХреЗ рдкреЗрдкрд░ рдиреИрдкрдХрд┐рди рдХрд╛ рдкреНрд░рдпреЛрдЧ рдЕрд╡рд╢реНрдп рдХрд░реЗрдВред\\n7. рдХрд╛рд░реНрдпрд╕реНрдерд▓ рдкрд░ рдХрд╛рд░реНрдп рдХрд░рдиреЗ рдХреЗ рджреМрд░рд╛рди рдЬрд┐рди рдЬрдЧрд╣реЛрдВ рдкрд░ рдЖрдкрдХрд╛ рд╣рд╛рде рдЬреНрдпрд╛рджрд╛ рдЬрд╛рддрд╛ рд╣реИ, рдЙрди\\nрд╕реНрдерд╛рдиреЛрдВ рдХреЛ рдПрд▓реНрдХреЛрд╣рд▓ рд╕реНрд╡реЙрдм(Alchohol Swab) рд╕реЗ рдзреЛрдиреЗ рдХрд╛ рдкреНрд░рдпрддреНрди рдХрд░реЗрдВред\\nрзк. рдЕрдкрдиреЗ рдореЛрдмрд╛рдЗрд▓ рдлреЛрдирдХреА рд╕реНрдХреНрд░реАрди рдХреЛ рдпрдерд╛рд╕рдореНрднрд╡ рд╕рд╛рдл рд░рдЦреЗрдВред\\n9. рдореЛрдмрд╛рдЗрд▓ рдлреЛрди рдХреЛ рдХрд╛рди рдпрд╛ рдореБрдБрд╣ рдХреЗ рдХрд░реАрдм рдХрдо-рд╕реЗ-рдХрдо рд░рдЦреЗрдВред\\n10. рдкреЗрдЯ рднрд░рд╛рд░рдЦреЗрдВред рднреВрдЦреЗ рдирд░рд╣реЗрдВред\\nрдЗрд╕ рддрд░рд╣ рдХреЗ рд╡рд╛рдпрд░рд╕ /рд╡реЗрдХреНрдЯреАрд░рд┐рдпрд╛ рднреВрдЦреЗ рд░рд╣рдиреЗ рд╡рд╛рд▓реЗ рд╡реНрдпрдХреНрддрд┐рдпреЛрдВ рдкрд░ рдЬреНрдпрд╛рджрд╛ рддреЗрдЬреА рд╕реЗ рдЕрдкрдирд╛\\nрджреБрд╖реНрдкреНрд░рднрд╛рд╡ рдбрд╛рд▓рддреЗ рд╣реИрдВред\\n11. рдХреЛрд░реЛрдирд╛ рд╡рд╛рдпрд░рд╕ рдЕрдзрд┐рдХ рддрд╛рдкрдорд╛рди рдореЗрдВ рдирд╣реАрдВ рдЯрд┐рдХрддрд╛ рд╣реИред рддрд╛рдкрдорд╛рди рдЬреИрд╕реЗ рд╣реА 30 - 35 рдбрд┐рдЧреНрд░реА\\nрдкрд╣реБрдБрдЪреЗрдЧрд╛ рдХреЛрд░реЛрдирд╛ рд╡рд╛рдпрд░рд╕ рдЦреБрдж-рдмрдЦреБрдж рдирд┐рд╖реНрдкреНрд░рднрд╛рд╡реА рд╣реЛ рдЬрд╛рдпреЗрдЧрд╛ред\\n12. рдХрд┐рд╕реА рднреА рдЕрдлрд╡рд╛рд╣ рдХрд╛ рд╣рд┐рд╕реНрд╕рд╛ рди рдмрдиреЗрдВ, рдЬрд╛рдЧрд░реВрдХрддрд╛ рд╣реА рдЖрдкрдХрд╛ рдмрдЪрд╛рд╡ рд╣реИред\\n', 'рдЬрд░реВрд░реА рд╕реВрдЪрдирд╛\\nрдкреБрд▓рд┐рд╕ рдХреА рдЧрд╛рдбрд╝реА рдЖрддреА рджреЗрдЦрдХрд░ рдШрд░\\nрдореЗрдВ рднрд╛рдЧ рдЬрд╛рдирд╛ рдФрд░ рдлрд┐рд░ рдЧрд╛рдбрд╝реА рдЬрд╛рддреЗ\\nрд╣реА рдмрд╛рд╣рд░ рдЖ рдЬрд╛рдирд╛ рдпрд╣ рдзреЛрдХрд╛ рдЖрдк\\nрдкреБрд▓рд┐рд╕ рдХреЛ рдирд╣реАрдВ рдЕрдкрдиреЗ рдкрд░рд┐рд╡рд╛рд░ рдФрд░\\nрд╕реНрд╡рдпрдВ рдХреЛ рджреЗ рд░рд╣реЗ рд╣реЛредрее\\nPlease Stay Home And Be Safe\\n', '', 'MelkaniQuotes\\nрдЭреВрдареА рдмрд╛рдд рдкрд░ рдЬреЛ рд╡рд╛рд╣\\nрдХрд░реЗрдВрдЧреЗ\\nрд╡рд╣реА рд▓реЛрдЧ рдЖрдкрдХреЛ рддрдмрд╛рд╣\\nрдХрд░реЗрдВрдЧреЗ\\nMelkani\\nQuotes\\n')], tensor([[ 873,    1,  144,    1,    1,    1,    1,    1,    1,  402,    1,    1,\n",
      "            1,    1,    1,    1,  408,   57,    1, 4020, 1100,   68,   11,   81,\n",
      "         4057,    1,  109,    1,   23,  207, 4020,   19, 5031, 1151,  244, 2692,\n",
      "         3076, 1507,  412,    1,  857,   19, 3608, 1486,   17,   44,  336, 1742,\n",
      "          275,  732],\n",
      "        [ 751,  751,    1,  950, 1035, 4096,    1,    1, 4970, 1049, 2689, 2689,\n",
      "          432, 3786,   11,   81, 4705,    1,    1,    1,    1, 1065,   27,  207,\n",
      "            1,   44,   30, 1295,   27,  129,    1,  139,   30,    1,   41, 1761,\n",
      "           81,  127,   27,   23,  182,  183,  309,  498,  129,   11,  341, 1097,\n",
      "           29,  277],\n",
      "        [ 182,  579,   29,  742,    1,   29, 4282,  604,   79,  736,  480, 1111,\n",
      "         1111,  130,    1,  201, 1398,   44,    1,    1, 1194,  303,   10, 1124,\n",
      "          660,   57,  182,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [1387,   90,   57,  185,  186,    1,    1,  139,  733,   57,  677,  218,\n",
      "           44, 4062,    1,    1,  202, 4174,    1,    1,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1,    1,    1,    1,    1,  182,  183,    1,    1,  319,    1,   27,\n",
      "          470, 1097, 2158, 1848,   24,  604,   27, 2765,   46,    1, 1994,  480,\n",
      "          303, 3272,  117,   57, 5076, 1345,   27,    1, 3246,   29,    1, 3603,\n",
      "            1, 1348,   29, 2032,    1, 3242, 1503,    1,   27, 2004, 4429, 2138,\n",
      "          488,    1],\n",
      "        [ 489, 1049,  742,   19, 1050, 1051,  969,  604,   27, 1052, 1053,  114,\n",
      "          746, 1050, 1054,   41,  736,  530, 1053,  342, 1055,  109,  742,   57,\n",
      "           37,   24, 1056,  114,  406,   57, 1057,   68,  135, 1058, 1059, 1060,\n",
      "         1061, 1062, 1063, 1064,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [   1, 1263,  550,   32,   23,    1, 2582, 1957,  364, 1762, 2580, 2582,\n",
      "            1,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]]))\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(zip(validation_loader, valid_seq_loader)):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in vocab2index.items():\n",
    "#     if v==102:\n",
    "#         print (k)\n",
    "\n",
    "# vocab2index[\"рдХрд░\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pretrained_weights, num_labels):\n",
    "        super().__init__()\n",
    "        # LSTM layers\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_weights))\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 100)\n",
    "        #self.dropout = nn.Dropout(0.2)\n",
    "        # ResNet layers\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Replace the default ResNet18 classifier layer \n",
    "        classifier_input = self.resnet.fc.in_features\n",
    "        classifier = nn.Sequential(nn.Linear(classifier_input, 100), \n",
    "                             nn.LogSoftmax(dim=1)) \n",
    "        self.resnet.fc = classifier\n",
    "        self.fusion_classifier = nn.Linear(200,2)\n",
    "        \n",
    "    def forward(self, x1, x2): # image vector, encoded image text\n",
    "        print(\"x1:\",x1)\n",
    "        print(\"x2\",x2)\n",
    "        # Image\n",
    "        x1_out = self.resnet(x1)\n",
    "        # Text\n",
    "        x2_embed = self.embeddings(x2)\n",
    "        #x2_dropout = self.dropout(x2_embed)\n",
    "        print(\"img representation:\",x1_out)\n",
    "        print(\"\")\n",
    "        lstm_out, (ht, ct) = self.lstm(x2_embed)\n",
    "        x2_out = self.linear(ht[-1])\n",
    "        print(\"text representation:\",x2_out)\n",
    "        print(\"\")\n",
    "        # Concatenation\n",
    "        fused = torch.cat([x2_out, x1_out], dim=1)\n",
    "        print(\"fused:\", fused)\n",
    "\n",
    "        return self.fusion_classifier(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FusionModel(vocab_size=vocab_size, embedding_dim=300, hidden_dim=5, pretrained_weights=pretrained_weights,\n",
    "                    num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, epochs, lr, train_loader, train_seq_loader):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, data in enumerate(zip(train_loader, train_seq_loader)):\n",
    "        #for data in zip(validation_loader, valid_seq_loader): \n",
    "            img_vectors, text_sequences, y_train = data[0][0], data[1], data[0][1]      \n",
    "#             x = x.long()\n",
    "#             y = y.long()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(img_vectors, text_sequences)\n",
    "            loss = F.cross_entropy(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y_train.shape[0]\n",
    "            total += y_train.shape[0]\n",
    "        val_loss, val_acc = validation_metrics(model, validation_loader, valid_seq_loader)\n",
    "        print(\"train loss %.3f, val loss %.3f, val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
    "\n",
    "def validation_metrics (model, validation_loader=validation_loader, valid_seq_loader=valid_seq_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for i, data in enumerate(zip(validation_loader, valid_seq_loader)):\n",
    "        #\n",
    "        img_vectors, text_sequences, y_valid = data[0][0], data[1], data[0][1] \n",
    "#         x = x.long()\n",
    "#         y = y.long()\n",
    "        y_hat = model(img_vectors, text_sequences)\n",
    "        loss = F.cross_entropy(y_hat, y_valid)\n",
    "        print(\"y_hat:\",y_hat)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        print(\"pred:\",pred)\n",
    "        correct += (pred == y_valid).float().sum()\n",
    "        total += y_valid.shape[0]\n",
    "        sum_loss += loss.item()*y_valid.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2884, -1.8953],\n",
      "        [-1.1243, -1.7167],\n",
      "        [-1.3596, -1.9504],\n",
      "        [-0.7396, -1.2463],\n",
      "        [-0.9927, -1.5336],\n",
      "        [-1.1708, -1.7369],\n",
      "        [-1.0991, -1.6546],\n",
      "        [-0.9892, -1.5298]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[1.4987, 2.9468],\n",
      "        [1.0020, 2.0537],\n",
      "        [1.0462, 2.1332],\n",
      "        [1.3739, 2.7223],\n",
      "        [1.4643, 2.8850],\n",
      "        [0.9805, 2.0152],\n",
      "        [1.5569, 3.0513],\n",
      "        [1.6277, 3.1998]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[-1.4104,  1.8417],\n",
      "        [-2.2062,  2.5288],\n",
      "        [-2.1078,  2.4641],\n",
      "        [-1.9090,  2.3783],\n",
      "        [-3.5514,  3.4589],\n",
      "        [-1.8618,  2.1805],\n",
      "        [-2.8620,  2.9453],\n",
      "        [-1.9153,  2.2209]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[-0.7397,  3.7871],\n",
      "        [-0.8005,  4.2924],\n",
      "        [-0.7056,  3.8461],\n",
      "        [-0.6546,  3.0524],\n",
      "        [-0.8033,  4.3144],\n",
      "        [-0.6357,  3.3473],\n",
      "        [-0.5970,  2.5743],\n",
      "        [-0.8114,  4.3884]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[ 3.2491, -0.0924],\n",
      "        [ 3.7636, -0.0913],\n",
      "        [ 3.0767, -0.0783],\n",
      "        [ 3.4551, -0.0433],\n",
      "        [ 3.2997, -0.0923],\n",
      "        [ 3.7194, -0.1184],\n",
      "        [ 3.1366, -0.0927],\n",
      "        [ 3.3639, -0.0915]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[3.1076, 3.3665],\n",
      "        [2.9885, 3.2171],\n",
      "        [2.9229, 3.1435],\n",
      "        [2.6458, 2.7746],\n",
      "        [2.9673, 3.1934],\n",
      "        [3.2854, 3.5508],\n",
      "        [2.6459, 2.7833],\n",
      "        [3.3530, 3.6109]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[1.8725, 0.7687],\n",
      "        [3.0440, 1.1827],\n",
      "        [2.6195, 1.0221],\n",
      "        [2.2354, 0.8919],\n",
      "        [2.0895, 0.8425],\n",
      "        [2.6177, 1.0214],\n",
      "        [2.1738, 0.8710],\n",
      "        [2.3026, 0.9147]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[ 0.2996, -4.5177],\n",
      "        [ 0.2281, -3.6953],\n",
      "        [ 0.2778, -4.2672],\n",
      "        [ 0.2484, -3.9294],\n",
      "        [ 0.2122, -3.5127],\n",
      "        [ 0.1878, -3.2295],\n",
      "        [ 0.0953, -2.3754],\n",
      "        [ 0.1872, -3.1774]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[1.7979, 3.0945],\n",
      "        [1.7608, 3.0028],\n",
      "        [2.0924, 3.4932],\n",
      "        [2.3150, 3.8819],\n",
      "        [2.4872, 4.0663],\n",
      "        [1.7597, 3.0010],\n",
      "        [2.1784, 3.6145],\n",
      "        [1.9223, 3.2463]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[-1.9439, -1.5731],\n",
      "        [-2.1798, -1.7047],\n",
      "        [-2.4968, -1.9440],\n",
      "        [-3.0068, -2.1957],\n",
      "        [-2.6307, -1.9437],\n",
      "        [-2.8776, -2.1188],\n",
      "        [-2.9640, -2.1605],\n",
      "        [-3.0625, -2.2219]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[-0.5302, -1.9631],\n",
      "        [-0.4607, -1.7227],\n",
      "        [-0.5402, -2.0031],\n",
      "        [-0.6628, -2.5553],\n",
      "        [-0.7081, -2.7597],\n",
      "        [-0.5223, -1.9440],\n",
      "        [-0.5130, -2.0314],\n",
      "        [-0.6469, -2.5003]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[4.0986, 1.5765],\n",
      "        [3.8484, 1.4691],\n",
      "        [4.7859, 1.8713],\n",
      "        [3.4353, 1.2500],\n",
      "        [3.7087, 1.3821],\n",
      "        [3.4332, 1.2910],\n",
      "        [2.7405, 0.9744],\n",
      "        [3.6016, 1.3633]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[-1.0090, -3.0735]], grad_fn=<AddmmBackward>)\n",
      "tensor([0])\n",
      "train loss 1.239, val loss 1.118, val accuracy 0.546\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-4cc2d16c1c24>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, lr, train_loader, train_seq_loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_seq_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#for data in zip(validation_loader, valid_seq_loader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mimg_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f014d0fe509e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageAnnotatorClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimg_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mimg_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f014d0fe509e>\u001b[0m in \u001b[0;36mget_image_text\u001b[0;34m(self, path, client)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mimgByteArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgByteArr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PNG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mimg_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgByteArr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tattle/content-relevance/env/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(model=model, epochs=10, lr=0.01, train_loader=train_loader, train_seq_loader=train_seq_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img representation: tensor([[-4.2521, -4.2464, -4.4741, -4.5547, -4.5478, -5.5457, -5.3049, -5.1204,\n",
      "         -5.1457, -5.2056, -4.5313, -5.0253, -4.7385, -4.7661, -4.5265, -4.2586,\n",
      "         -3.3594, -4.3817, -4.1012, -5.8242, -5.5435, -5.0205, -5.0595, -4.6622,\n",
      "         -4.5196, -4.2702, -4.5995, -4.6876, -5.2176, -3.2149, -4.6365, -4.9898,\n",
      "         -5.5991, -4.2091, -4.7610, -4.1638, -3.8122, -4.7662, -5.0462, -4.9526,\n",
      "         -4.7008, -4.5671, -4.3898, -4.1583, -4.2191, -3.2409, -4.4813, -4.4752,\n",
      "         -2.9030, -4.5563, -4.8537, -4.8357, -4.2699, -4.6099, -5.8208, -5.1968,\n",
      "         -4.3736, -4.7389, -5.1744, -4.9667, -3.9274, -5.3632, -4.8872, -5.0379,\n",
      "         -5.2167, -5.8661, -4.7592, -5.0030, -5.5042, -4.4636, -4.7795, -5.1121,\n",
      "         -4.3879, -4.8093, -5.2627, -5.0186, -5.2898, -4.6608, -4.6598, -5.9072,\n",
      "         -5.5910, -4.7094, -4.7134, -5.2310, -5.1905, -4.3843, -4.2540, -4.8409,\n",
      "         -4.6072, -4.9843, -5.3077, -4.9965, -4.7092, -5.1058, -4.5060, -6.0548,\n",
      "         -5.5167, -5.2616, -5.4040, -5.0175]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "text representation: tensor([[-0.3316, -0.0904,  0.1169, -0.0530,  0.1175, -0.2512,  0.2783,  0.0231,\n",
      "          0.1025, -0.3628,  0.1759, -0.4433,  0.3993,  0.0381, -0.1814, -0.3402,\n",
      "         -0.1008,  0.3423, -0.2176, -0.3097,  0.1526, -0.4573, -0.1827,  0.1051,\n",
      "         -0.0229, -0.1090,  0.2532,  0.1140,  0.3246,  0.0070, -0.4006, -0.1814,\n",
      "          0.2676, -0.3184,  0.2777,  0.2097, -0.3486, -0.2332,  0.0375,  0.1062,\n",
      "          0.1179,  0.0943, -0.3436, -0.5155, -0.1757,  0.1072, -0.3697,  0.1476,\n",
      "         -0.1967,  0.3084,  0.0094,  0.3308, -0.2688, -0.1747, -0.4722, -0.4758,\n",
      "          0.2690, -0.0164,  0.2085,  0.4478, -0.3820, -0.4052,  0.3868, -0.3084,\n",
      "          0.0341, -0.1685,  0.2567,  0.1128,  0.4728,  0.2844,  0.4709, -0.4372,\n",
      "         -0.0241, -0.4189, -0.4077,  0.4309,  0.3337, -0.0597,  0.1552, -0.3926,\n",
      "         -0.1624, -0.2317, -0.2512, -0.1209,  0.0442,  0.4739,  0.2705, -0.3573,\n",
      "         -0.0099, -0.4361,  0.3747,  0.0482,  0.2820,  0.1840,  0.2053,  0.3253,\n",
      "          0.2975,  0.2377,  0.2658,  0.1077]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "fused: tensor([[-0.3316, -0.0904,  0.1169, -0.0530,  0.1175, -0.2512,  0.2783,  0.0231,\n",
      "          0.1025, -0.3628,  0.1759, -0.4433,  0.3993,  0.0381, -0.1814, -0.3402,\n",
      "         -0.1008,  0.3423, -0.2176, -0.3097,  0.1526, -0.4573, -0.1827,  0.1051,\n",
      "         -0.0229, -0.1090,  0.2532,  0.1140,  0.3246,  0.0070, -0.4006, -0.1814,\n",
      "          0.2676, -0.3184,  0.2777,  0.2097, -0.3486, -0.2332,  0.0375,  0.1062,\n",
      "          0.1179,  0.0943, -0.3436, -0.5155, -0.1757,  0.1072, -0.3697,  0.1476,\n",
      "         -0.1967,  0.3084,  0.0094,  0.3308, -0.2688, -0.1747, -0.4722, -0.4758,\n",
      "          0.2690, -0.0164,  0.2085,  0.4478, -0.3820, -0.4052,  0.3868, -0.3084,\n",
      "          0.0341, -0.1685,  0.2567,  0.1128,  0.4728,  0.2844,  0.4709, -0.4372,\n",
      "         -0.0241, -0.4189, -0.4077,  0.4309,  0.3337, -0.0597,  0.1552, -0.3926,\n",
      "         -0.1624, -0.2317, -0.2512, -0.1209,  0.0442,  0.4739,  0.2705, -0.3573,\n",
      "         -0.0099, -0.4361,  0.3747,  0.0482,  0.2820,  0.1840,  0.2053,  0.3253,\n",
      "          0.2975,  0.2377,  0.2658,  0.1077, -4.2521, -4.2464, -4.4741, -4.5547,\n",
      "         -4.5478, -5.5457, -5.3049, -5.1204, -5.1457, -5.2056, -4.5313, -5.0253,\n",
      "         -4.7385, -4.7661, -4.5265, -4.2586, -3.3594, -4.3817, -4.1012, -5.8242,\n",
      "         -5.5435, -5.0205, -5.0595, -4.6622, -4.5196, -4.2702, -4.5995, -4.6876,\n",
      "         -5.2176, -3.2149, -4.6365, -4.9898, -5.5991, -4.2091, -4.7610, -4.1638,\n",
      "         -3.8122, -4.7662, -5.0462, -4.9526, -4.7008, -4.5671, -4.3898, -4.1583,\n",
      "         -4.2191, -3.2409, -4.4813, -4.4752, -2.9030, -4.5563, -4.8537, -4.8357,\n",
      "         -4.2699, -4.6099, -5.8208, -5.1968, -4.3736, -4.7389, -5.1744, -4.9667,\n",
      "         -3.9274, -5.3632, -4.8872, -5.0379, -5.2167, -5.8661, -4.7592, -5.0030,\n",
      "         -5.5042, -4.4636, -4.7795, -5.1121, -4.3879, -4.8093, -5.2627, -5.0186,\n",
      "         -5.2898, -4.6608, -4.6598, -5.9072, -5.5910, -4.7094, -4.7134, -5.2310,\n",
      "         -5.1905, -4.3843, -4.2540, -4.8409, -4.6072, -4.9843, -5.3077, -4.9965,\n",
      "         -4.7092, -5.1058, -4.5060, -6.0548, -5.5167, -5.2616, -5.4040, -5.0175]],\n",
      "       grad_fn=<CatBackward>)\n",
      "img representation: tensor([[-11.9913,  -3.7826, -12.5833, -11.7889, -11.2992,  -4.7991,  -4.4945,\n",
      "         -12.6855, -11.9649, -12.2276, -11.8422, -11.8447, -12.0405,  -3.7416,\n",
      "         -11.5485, -11.9999, -10.8261,  -3.6566, -12.4659,  -5.4574,  -3.5221,\n",
      "         -13.0376,  -4.1919, -12.3176,  -4.1105, -12.0193, -11.7328, -11.7507,\n",
      "          -4.4628, -11.2013, -12.0474,  -4.1130,  -5.0844, -11.2223,  -3.6835,\n",
      "          -3.1347, -11.4154, -12.1186,  -4.2668,  -4.5831, -11.7406,  -4.6845,\n",
      "          -2.9980,  -3.2289, -12.1989, -10.6418,  -4.1819, -11.4468, -10.9723,\n",
      "         -11.6317,  -4.1813, -12.5192,  -3.4268,  -3.2935,  -5.4684, -12.4832,\n",
      "          -3.8902, -11.5476,  -4.6908,  -4.4863,  -3.9324,  -4.3077, -12.5412,\n",
      "          -3.7257, -12.4882,  -4.7619, -12.2484,  -4.2403, -12.7177, -11.5256,\n",
      "          -4.2174, -12.0858,  -3.4705,  -3.7659, -12.0408,  -3.4726, -12.9526,\n",
      "          -3.7892,  -4.5419, -12.8421, -12.8729,  -3.7096, -11.8118, -12.6065,\n",
      "          -4.6220,  -3.4215,  -3.1535,  -4.5739,  -4.1453,  -4.8709, -12.8969,\n",
      "          -4.0048,  -3.8581,  -4.7366,  -3.8848, -12.9636,  -4.4669,  -5.0619,\n",
      "          -5.0294,  -3.8282],\n",
      "        [-11.8447,  -3.9464, -11.2609, -12.2781, -12.1543,  -3.9545,  -4.0019,\n",
      "         -12.2932, -11.7808, -12.0304, -13.2854, -12.1163, -12.5795,  -3.8014,\n",
      "         -12.4147, -12.2848, -11.4008,  -3.2728, -11.7993,  -4.4218,  -5.2945,\n",
      "         -12.2411,  -3.8866, -12.8508,  -4.0057, -11.6302, -11.6989, -11.8493,\n",
      "          -5.2403,  -9.8713, -11.6305,  -4.2098,  -4.4167, -10.9850,  -3.9780,\n",
      "          -3.3411, -10.9573, -12.2791,  -3.7425,  -4.7395, -11.8754,  -4.2133,\n",
      "          -3.4015,  -3.7881, -12.2334, -10.7329,  -3.8347, -11.5902, -11.0319,\n",
      "         -12.3321,  -3.6539, -12.1957,  -4.0869,  -3.7605,  -5.3315, -12.1294,\n",
      "          -4.1113, -11.4262,  -4.1386,  -4.7603,  -3.1940,  -5.0062, -11.8343,\n",
      "          -4.7427, -13.0524,  -5.2751, -12.5379,  -3.4173, -13.7172, -11.6907,\n",
      "          -3.8422, -12.7018,  -4.2619,  -4.5733, -12.8526,  -4.5814, -12.3846,\n",
      "          -4.2394,  -4.2135, -13.3160, -14.1304,  -4.3743, -11.3125, -12.6819,\n",
      "          -5.7403,  -2.4686,  -4.4718,  -3.4121,  -4.4958,  -3.9187, -12.9499,\n",
      "          -4.2822,  -3.5968,  -4.5703,  -3.0550, -13.7008,  -4.8083,  -3.8884,\n",
      "          -4.3756,  -4.7645]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "text representation: tensor([[-0.2103,  0.0282,  0.1160, -0.2030,  0.2275, -0.3258,  0.3164, -0.0594,\n",
      "         -0.0302, -0.4492,  0.2578, -0.5199,  0.3643, -0.1017, -0.0760, -0.3475,\n",
      "          0.0618,  0.2056, -0.1329, -0.3692,  0.1208, -0.4269, -0.2222, -0.0311,\n",
      "          0.1317,  0.0079,  0.1631,  0.0597,  0.2512, -0.0955, -0.4269, -0.1077,\n",
      "          0.1878, -0.3261,  0.2103,  0.2665, -0.3859, -0.2376, -0.0457,  0.1387,\n",
      "          0.0695,  0.0059, -0.4196, -0.5229, -0.2515,  0.0183, -0.4664,  0.2570,\n",
      "         -0.2655,  0.3314,  0.0859,  0.2217, -0.3589, -0.1008, -0.5668, -0.3855,\n",
      "          0.3541, -0.0499,  0.0824,  0.4113, -0.3091, -0.3748,  0.3068, -0.4256,\n",
      "         -0.0429, -0.1509,  0.3975, -0.0324,  0.4924,  0.3035,  0.5576, -0.5181,\n",
      "          0.0050, -0.3126, -0.4028,  0.5135,  0.2628, -0.1475,  0.2597, -0.2604,\n",
      "         -0.2911, -0.2099, -0.3504, -0.1290,  0.1782,  0.5373,  0.3635, -0.3286,\n",
      "          0.0037, -0.3749,  0.3768,  0.0397,  0.3845,  0.2386,  0.2572,  0.2487,\n",
      "          0.3506,  0.2177,  0.3348,  0.0192],\n",
      "        [-0.3064, -0.0731,  0.1515, -0.0403,  0.1039, -0.2729,  0.2541,  0.0074,\n",
      "          0.1336, -0.3843,  0.1595, -0.4597,  0.3794,  0.0538, -0.1590, -0.3223,\n",
      "         -0.0756,  0.3078, -0.1969, -0.3080,  0.1557, -0.4400, -0.1596,  0.1113,\n",
      "          0.0119, -0.0829,  0.2829,  0.0966,  0.3460,  0.0145, -0.4161, -0.1750,\n",
      "          0.2473, -0.3320,  0.2608,  0.2286, -0.3648, -0.2163,  0.0551,  0.0862,\n",
      "          0.1023,  0.0678, -0.3626, -0.4877, -0.1713,  0.0801, -0.3612,  0.1708,\n",
      "         -0.1898,  0.3357,  0.0265,  0.3385, -0.2544, -0.1654, -0.4658, -0.4417,\n",
      "          0.2882, -0.0413,  0.2232,  0.4604, -0.3634, -0.4198,  0.4052, -0.3342,\n",
      "          0.0417, -0.1471,  0.2774,  0.0922,  0.4536,  0.3100,  0.4600, -0.4522,\n",
      "         -0.0313, -0.4304, -0.3960,  0.4074,  0.3241, -0.0349,  0.1856, -0.3849,\n",
      "         -0.1532, -0.2212, -0.2809, -0.1437,  0.0438,  0.4926,  0.2504, -0.3431,\n",
      "          0.0075, -0.4343,  0.3887,  0.0356,  0.2916,  0.2059,  0.2231,  0.3121,\n",
      "          0.3073,  0.2508,  0.2986,  0.1143]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "fused: tensor([[-2.1026e-01,  2.8228e-02,  1.1598e-01, -2.0295e-01,  2.2751e-01,\n",
      "         -3.2583e-01,  3.1641e-01, -5.9412e-02, -3.0198e-02, -4.4921e-01,\n",
      "          2.5775e-01, -5.1989e-01,  3.6434e-01, -1.0167e-01, -7.5966e-02,\n",
      "         -3.4752e-01,  6.1750e-02,  2.0556e-01, -1.3289e-01, -3.6923e-01,\n",
      "          1.2079e-01, -4.2692e-01, -2.2221e-01, -3.1149e-02,  1.3166e-01,\n",
      "          7.8980e-03,  1.6312e-01,  5.9683e-02,  2.5119e-01, -9.5521e-02,\n",
      "         -4.2688e-01, -1.0769e-01,  1.8782e-01, -3.2608e-01,  2.1032e-01,\n",
      "          2.6647e-01, -3.8592e-01, -2.3762e-01, -4.5745e-02,  1.3866e-01,\n",
      "          6.9492e-02,  5.8834e-03, -4.1962e-01, -5.2289e-01, -2.5153e-01,\n",
      "          1.8328e-02, -4.6635e-01,  2.5704e-01, -2.6550e-01,  3.3144e-01,\n",
      "          8.5872e-02,  2.2172e-01, -3.5892e-01, -1.0083e-01, -5.6681e-01,\n",
      "         -3.8555e-01,  3.5410e-01, -4.9865e-02,  8.2378e-02,  4.1126e-01,\n",
      "         -3.0912e-01, -3.7478e-01,  3.0680e-01, -4.2557e-01, -4.2914e-02,\n",
      "         -1.5094e-01,  3.9750e-01, -3.2357e-02,  4.9242e-01,  3.0353e-01,\n",
      "          5.5760e-01, -5.1812e-01,  5.0291e-03, -3.1261e-01, -4.0284e-01,\n",
      "          5.1346e-01,  2.6280e-01, -1.4754e-01,  2.5967e-01, -2.6036e-01,\n",
      "         -2.9109e-01, -2.0990e-01, -3.5036e-01, -1.2897e-01,  1.7818e-01,\n",
      "          5.3731e-01,  3.6346e-01, -3.2863e-01,  3.6723e-03, -3.7493e-01,\n",
      "          3.7682e-01,  3.9748e-02,  3.8449e-01,  2.3860e-01,  2.5715e-01,\n",
      "          2.4867e-01,  3.5055e-01,  2.1771e-01,  3.3475e-01,  1.9164e-02,\n",
      "         -1.1991e+01, -3.7826e+00, -1.2583e+01, -1.1789e+01, -1.1299e+01,\n",
      "         -4.7991e+00, -4.4945e+00, -1.2685e+01, -1.1965e+01, -1.2228e+01,\n",
      "         -1.1842e+01, -1.1845e+01, -1.2040e+01, -3.7416e+00, -1.1548e+01,\n",
      "         -1.2000e+01, -1.0826e+01, -3.6566e+00, -1.2466e+01, -5.4574e+00,\n",
      "         -3.5221e+00, -1.3038e+01, -4.1919e+00, -1.2318e+01, -4.1105e+00,\n",
      "         -1.2019e+01, -1.1733e+01, -1.1751e+01, -4.4628e+00, -1.1201e+01,\n",
      "         -1.2047e+01, -4.1130e+00, -5.0844e+00, -1.1222e+01, -3.6835e+00,\n",
      "         -3.1347e+00, -1.1415e+01, -1.2119e+01, -4.2668e+00, -4.5831e+00,\n",
      "         -1.1741e+01, -4.6845e+00, -2.9980e+00, -3.2289e+00, -1.2199e+01,\n",
      "         -1.0642e+01, -4.1819e+00, -1.1447e+01, -1.0972e+01, -1.1632e+01,\n",
      "         -4.1813e+00, -1.2519e+01, -3.4268e+00, -3.2935e+00, -5.4684e+00,\n",
      "         -1.2483e+01, -3.8902e+00, -1.1548e+01, -4.6908e+00, -4.4863e+00,\n",
      "         -3.9324e+00, -4.3077e+00, -1.2541e+01, -3.7257e+00, -1.2488e+01,\n",
      "         -4.7619e+00, -1.2248e+01, -4.2403e+00, -1.2718e+01, -1.1526e+01,\n",
      "         -4.2174e+00, -1.2086e+01, -3.4705e+00, -3.7659e+00, -1.2041e+01,\n",
      "         -3.4726e+00, -1.2953e+01, -3.7892e+00, -4.5419e+00, -1.2842e+01,\n",
      "         -1.2873e+01, -3.7096e+00, -1.1812e+01, -1.2606e+01, -4.6220e+00,\n",
      "         -3.4215e+00, -3.1535e+00, -4.5739e+00, -4.1453e+00, -4.8709e+00,\n",
      "         -1.2897e+01, -4.0048e+00, -3.8581e+00, -4.7366e+00, -3.8848e+00,\n",
      "         -1.2964e+01, -4.4669e+00, -5.0619e+00, -5.0294e+00, -3.8282e+00],\n",
      "        [-3.0637e-01, -7.3115e-02,  1.5151e-01, -4.0313e-02,  1.0391e-01,\n",
      "         -2.7288e-01,  2.5407e-01,  7.3676e-03,  1.3357e-01, -3.8432e-01,\n",
      "          1.5947e-01, -4.5970e-01,  3.7942e-01,  5.3770e-02, -1.5898e-01,\n",
      "         -3.2229e-01, -7.5596e-02,  3.0779e-01, -1.9686e-01, -3.0801e-01,\n",
      "          1.5575e-01, -4.3997e-01, -1.5958e-01,  1.1131e-01,  1.1892e-02,\n",
      "         -8.2854e-02,  2.8287e-01,  9.6609e-02,  3.4600e-01,  1.4528e-02,\n",
      "         -4.1609e-01, -1.7496e-01,  2.4727e-01, -3.3202e-01,  2.6076e-01,\n",
      "          2.2861e-01, -3.6484e-01, -2.1629e-01,  5.5140e-02,  8.6196e-02,\n",
      "          1.0226e-01,  6.7790e-02, -3.6263e-01, -4.8768e-01, -1.7135e-01,\n",
      "          8.0051e-02, -3.6123e-01,  1.7076e-01, -1.8977e-01,  3.3566e-01,\n",
      "          2.6527e-02,  3.3855e-01, -2.5443e-01, -1.6536e-01, -4.6582e-01,\n",
      "         -4.4171e-01,  2.8825e-01, -4.1344e-02,  2.2324e-01,  4.6043e-01,\n",
      "         -3.6339e-01, -4.1983e-01,  4.0520e-01, -3.3422e-01,  4.1694e-02,\n",
      "         -1.4709e-01,  2.7744e-01,  9.2178e-02,  4.5364e-01,  3.0998e-01,\n",
      "          4.5999e-01, -4.5217e-01, -3.1254e-02, -4.3045e-01, -3.9602e-01,\n",
      "          4.0738e-01,  3.2405e-01, -3.4936e-02,  1.8557e-01, -3.8488e-01,\n",
      "         -1.5318e-01, -2.2119e-01, -2.8086e-01, -1.4372e-01,  4.3834e-02,\n",
      "          4.9259e-01,  2.5044e-01, -3.4313e-01,  7.4635e-03, -4.3426e-01,\n",
      "          3.8869e-01,  3.5596e-02,  2.9161e-01,  2.0591e-01,  2.2310e-01,\n",
      "          3.1212e-01,  3.0726e-01,  2.5077e-01,  2.9863e-01,  1.1432e-01,\n",
      "         -1.1845e+01, -3.9464e+00, -1.1261e+01, -1.2278e+01, -1.2154e+01,\n",
      "         -3.9545e+00, -4.0019e+00, -1.2293e+01, -1.1781e+01, -1.2030e+01,\n",
      "         -1.3285e+01, -1.2116e+01, -1.2579e+01, -3.8014e+00, -1.2415e+01,\n",
      "         -1.2285e+01, -1.1401e+01, -3.2728e+00, -1.1799e+01, -4.4218e+00,\n",
      "         -5.2945e+00, -1.2241e+01, -3.8866e+00, -1.2851e+01, -4.0057e+00,\n",
      "         -1.1630e+01, -1.1699e+01, -1.1849e+01, -5.2403e+00, -9.8713e+00,\n",
      "         -1.1630e+01, -4.2098e+00, -4.4167e+00, -1.0985e+01, -3.9780e+00,\n",
      "         -3.3411e+00, -1.0957e+01, -1.2279e+01, -3.7425e+00, -4.7395e+00,\n",
      "         -1.1875e+01, -4.2133e+00, -3.4015e+00, -3.7881e+00, -1.2233e+01,\n",
      "         -1.0733e+01, -3.8347e+00, -1.1590e+01, -1.1032e+01, -1.2332e+01,\n",
      "         -3.6539e+00, -1.2196e+01, -4.0869e+00, -3.7605e+00, -5.3315e+00,\n",
      "         -1.2129e+01, -4.1113e+00, -1.1426e+01, -4.1386e+00, -4.7603e+00,\n",
      "         -3.1940e+00, -5.0062e+00, -1.1834e+01, -4.7427e+00, -1.3052e+01,\n",
      "         -5.2751e+00, -1.2538e+01, -3.4173e+00, -1.3717e+01, -1.1691e+01,\n",
      "         -3.8422e+00, -1.2702e+01, -4.2619e+00, -4.5733e+00, -1.2853e+01,\n",
      "         -4.5814e+00, -1.2385e+01, -4.2394e+00, -4.2135e+00, -1.3316e+01,\n",
      "         -1.4130e+01, -4.3743e+00, -1.1312e+01, -1.2682e+01, -5.7403e+00,\n",
      "         -2.4686e+00, -4.4718e+00, -3.4121e+00, -4.4958e+00, -3.9187e+00,\n",
      "         -1.2950e+01, -4.2822e+00, -3.5968e+00, -4.5703e+00, -3.0550e+00,\n",
      "         -1.3701e+01, -4.8083e+00, -3.8884e+00, -4.3756e+00, -4.7645e+00]],\n",
      "       grad_fn=<CatBackward>)\n",
      "y_hat: tensor([[ 13.5489, -14.5043],\n",
      "        [ 13.9271, -14.3401]], grad_fn=<AddmmBackward>)\n",
      "pred: tensor([0, 0])\n",
      "train loss 4.121, val loss 0.000, val accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img representation: tensor([[-11.8634,  -3.5502, -12.5868, -11.5374, -11.5819,  -4.5397,  -3.7741,\n",
      "         -12.0026, -12.0417, -12.6410, -11.9186, -12.4750, -12.8020,  -4.2791,\n",
      "         -11.7074, -11.7172, -10.8717,  -3.9249, -11.0223,  -5.0255,  -4.0409,\n",
      "         -12.3385,  -4.9010, -11.6947,  -3.9779, -10.9718, -11.3072, -11.6124,\n",
      "          -4.0879, -10.6153, -11.6457,  -4.1957,  -4.7426, -12.2339,  -4.7658,\n",
      "          -3.5958, -11.3617, -11.6555,  -3.8889,  -4.5319, -12.5150,  -4.3914,\n",
      "          -4.3513,  -3.6762, -10.7070, -10.1089,  -3.0840, -10.9793, -10.0362,\n",
      "         -11.9951,  -4.2718, -12.1493,  -4.2256,  -3.4949,  -3.9752, -11.8257,\n",
      "          -3.2105, -11.7752,  -4.6601,  -4.5970,  -2.3097,  -4.9880, -11.9044,\n",
      "          -4.8332, -12.7361,  -5.1199, -11.5616,  -4.3642, -12.2760, -11.3185,\n",
      "          -3.7257, -12.6843,  -3.3394,  -4.4739, -13.2273,  -5.1117, -12.5062,\n",
      "          -4.4007,  -4.1046, -11.7557, -11.9558,  -4.0044, -11.1070, -12.5791,\n",
      "          -4.1102,  -4.4747,  -3.6217,  -3.6227,  -3.7704,  -3.7628, -12.1570,\n",
      "          -4.2027,  -4.2135,  -3.4227,  -4.1878, -12.4906,  -5.3745,  -3.8763,\n",
      "          -5.1955,  -3.9700]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "text representation: tensor([[-0.3064, -0.0731,  0.1515, -0.0403,  0.1039, -0.2729,  0.2541,  0.0074,\n",
      "          0.1336, -0.3843,  0.1595, -0.4597,  0.3794,  0.0538, -0.1590, -0.3223,\n",
      "         -0.0756,  0.3078, -0.1969, -0.3080,  0.1557, -0.4400, -0.1596,  0.1113,\n",
      "          0.0119, -0.0829,  0.2829,  0.0966,  0.3460,  0.0145, -0.4161, -0.1750,\n",
      "          0.2473, -0.3320,  0.2608,  0.2286, -0.3648, -0.2163,  0.0551,  0.0862,\n",
      "          0.1023,  0.0678, -0.3626, -0.4877, -0.1713,  0.0801, -0.3612,  0.1708,\n",
      "         -0.1898,  0.3357,  0.0265,  0.3385, -0.2544, -0.1654, -0.4658, -0.4417,\n",
      "          0.2882, -0.0413,  0.2232,  0.4604, -0.3634, -0.4198,  0.4052, -0.3342,\n",
      "          0.0417, -0.1471,  0.2774,  0.0922,  0.4536,  0.3100,  0.4600, -0.4522,\n",
      "         -0.0313, -0.4304, -0.3960,  0.4074,  0.3241, -0.0349,  0.1856, -0.3849,\n",
      "         -0.1532, -0.2212, -0.2809, -0.1437,  0.0438,  0.4926,  0.2504, -0.3431,\n",
      "          0.0075, -0.4343,  0.3887,  0.0356,  0.2916,  0.2059,  0.2231,  0.3121,\n",
      "          0.3073,  0.2508,  0.2986,  0.1143]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "fused: tensor([[-3.0637e-01, -7.3115e-02,  1.5151e-01, -4.0313e-02,  1.0391e-01,\n",
      "         -2.7288e-01,  2.5407e-01,  7.3676e-03,  1.3357e-01, -3.8432e-01,\n",
      "          1.5947e-01, -4.5970e-01,  3.7942e-01,  5.3770e-02, -1.5898e-01,\n",
      "         -3.2229e-01, -7.5596e-02,  3.0779e-01, -1.9686e-01, -3.0801e-01,\n",
      "          1.5575e-01, -4.3997e-01, -1.5958e-01,  1.1131e-01,  1.1892e-02,\n",
      "         -8.2854e-02,  2.8287e-01,  9.6609e-02,  3.4600e-01,  1.4528e-02,\n",
      "         -4.1609e-01, -1.7496e-01,  2.4727e-01, -3.3202e-01,  2.6076e-01,\n",
      "          2.2861e-01, -3.6484e-01, -2.1629e-01,  5.5140e-02,  8.6196e-02,\n",
      "          1.0226e-01,  6.7790e-02, -3.6263e-01, -4.8768e-01, -1.7135e-01,\n",
      "          8.0051e-02, -3.6123e-01,  1.7076e-01, -1.8977e-01,  3.3566e-01,\n",
      "          2.6527e-02,  3.3855e-01, -2.5443e-01, -1.6536e-01, -4.6582e-01,\n",
      "         -4.4171e-01,  2.8825e-01, -4.1344e-02,  2.2324e-01,  4.6043e-01,\n",
      "         -3.6339e-01, -4.1983e-01,  4.0520e-01, -3.3422e-01,  4.1694e-02,\n",
      "         -1.4709e-01,  2.7744e-01,  9.2178e-02,  4.5364e-01,  3.0998e-01,\n",
      "          4.5999e-01, -4.5217e-01, -3.1254e-02, -4.3045e-01, -3.9602e-01,\n",
      "          4.0738e-01,  3.2405e-01, -3.4936e-02,  1.8557e-01, -3.8488e-01,\n",
      "         -1.5318e-01, -2.2119e-01, -2.8086e-01, -1.4372e-01,  4.3834e-02,\n",
      "          4.9259e-01,  2.5044e-01, -3.4313e-01,  7.4635e-03, -4.3426e-01,\n",
      "          3.8869e-01,  3.5596e-02,  2.9161e-01,  2.0591e-01,  2.2310e-01,\n",
      "          3.1212e-01,  3.0726e-01,  2.5077e-01,  2.9863e-01,  1.1432e-01,\n",
      "         -1.1863e+01, -3.5502e+00, -1.2587e+01, -1.1537e+01, -1.1582e+01,\n",
      "         -4.5397e+00, -3.7741e+00, -1.2003e+01, -1.2042e+01, -1.2641e+01,\n",
      "         -1.1919e+01, -1.2475e+01, -1.2802e+01, -4.2791e+00, -1.1707e+01,\n",
      "         -1.1717e+01, -1.0872e+01, -3.9249e+00, -1.1022e+01, -5.0255e+00,\n",
      "         -4.0409e+00, -1.2339e+01, -4.9010e+00, -1.1695e+01, -3.9779e+00,\n",
      "         -1.0972e+01, -1.1307e+01, -1.1612e+01, -4.0879e+00, -1.0615e+01,\n",
      "         -1.1646e+01, -4.1957e+00, -4.7426e+00, -1.2234e+01, -4.7658e+00,\n",
      "         -3.5958e+00, -1.1362e+01, -1.1656e+01, -3.8889e+00, -4.5319e+00,\n",
      "         -1.2515e+01, -4.3914e+00, -4.3513e+00, -3.6762e+00, -1.0707e+01,\n",
      "         -1.0109e+01, -3.0840e+00, -1.0979e+01, -1.0036e+01, -1.1995e+01,\n",
      "         -4.2718e+00, -1.2149e+01, -4.2256e+00, -3.4949e+00, -3.9752e+00,\n",
      "         -1.1826e+01, -3.2105e+00, -1.1775e+01, -4.6601e+00, -4.5970e+00,\n",
      "         -2.3097e+00, -4.9880e+00, -1.1904e+01, -4.8332e+00, -1.2736e+01,\n",
      "         -5.1199e+00, -1.1562e+01, -4.3642e+00, -1.2276e+01, -1.1318e+01,\n",
      "         -3.7257e+00, -1.2684e+01, -3.3394e+00, -4.4739e+00, -1.3227e+01,\n",
      "         -5.1117e+00, -1.2506e+01, -4.4007e+00, -4.1046e+00, -1.1756e+01,\n",
      "         -1.1956e+01, -4.0044e+00, -1.1107e+01, -1.2579e+01, -4.1102e+00,\n",
      "         -4.4747e+00, -3.6217e+00, -3.6227e+00, -3.7704e+00, -3.7628e+00,\n",
      "         -1.2157e+01, -4.2027e+00, -4.2135e+00, -3.4227e+00, -4.1878e+00,\n",
      "         -1.2491e+01, -5.3745e+00, -3.8763e+00, -5.1955e+00, -3.9700e+00]],\n",
      "       grad_fn=<CatBackward>)\n",
      "img representation: tensor([[-17.4329,  -3.7823, -18.0250, -17.2305, -16.7409,  -4.7988,  -4.4942,\n",
      "         -18.1271, -17.4065, -17.6692, -17.2838, -17.2863, -17.4821,  -3.7412,\n",
      "         -16.9901, -17.4415, -16.2678,  -3.6563, -17.9076,  -5.4571,  -3.5218,\n",
      "         -18.4792,  -4.1915, -17.7592,  -4.1102, -17.4609, -17.1744, -17.1923,\n",
      "          -4.4624, -16.6429, -17.4891,  -4.1126,  -5.0841, -16.6639,  -3.6831,\n",
      "          -3.1343, -16.8570, -17.5602,  -4.2664,  -4.5828, -17.1822,  -4.6842,\n",
      "          -2.9977,  -3.2286, -17.6405, -16.0835,  -4.1815, -16.8885, -16.4139,\n",
      "         -17.0733,  -4.1809, -17.9608,  -3.4265,  -3.2931,  -5.4681, -17.9248,\n",
      "          -3.8898, -16.9892,  -4.6905,  -4.4860,  -3.9320,  -4.3074, -17.9829,\n",
      "          -3.7254, -17.9298,  -4.7616, -17.6900,  -4.2400, -18.1593, -16.9672,\n",
      "          -4.2171, -17.5274,  -3.4701,  -3.7656, -17.4824,  -3.4723, -18.3942,\n",
      "          -3.7889,  -4.5415, -18.2837, -18.3145,  -3.7093, -17.2535, -18.0481,\n",
      "          -4.6217,  -3.4212,  -3.1531,  -4.5736,  -4.1450,  -4.8706, -18.3385,\n",
      "          -4.0044,  -3.8578,  -4.7362,  -3.8844, -18.4052,  -4.4666,  -5.0616,\n",
      "          -5.0290,  -3.8278],\n",
      "        [-17.2941,  -3.9461, -16.7102, -17.7275, -17.6036,  -3.9542,  -4.0016,\n",
      "         -17.7426, -17.2302, -17.4797, -18.7348, -17.5656, -18.0288,  -3.8010,\n",
      "         -17.8640, -17.7341, -16.8502,  -3.2725, -17.2487,  -4.4215,  -5.2942,\n",
      "         -17.6904,  -3.8863, -18.3002,  -4.0054, -17.0796, -17.1482, -17.2987,\n",
      "          -5.2400, -15.3207, -17.0798,  -4.2095,  -4.4163, -16.4343,  -3.9776,\n",
      "          -3.3407, -16.4067, -17.7284,  -3.7422,  -4.7391, -17.3247,  -4.2130,\n",
      "          -3.4011,  -3.7878, -17.6828, -16.1822,  -3.8344, -17.0395, -16.4813,\n",
      "         -17.7814,  -3.6535, -17.6450,  -4.0866,  -3.7601,  -5.3311, -17.5787,\n",
      "          -4.1109, -16.8756,  -4.1382,  -4.7599,  -3.1937,  -5.0059, -17.2836,\n",
      "          -4.7423, -18.5018,  -5.2747, -17.9872,  -3.4170, -19.1666, -17.1400,\n",
      "          -3.8418, -18.1512,  -4.2615,  -4.5730, -18.3019,  -4.5811, -17.8339,\n",
      "          -4.2390,  -4.2131, -18.7654, -19.5797,  -4.3739, -16.7618, -18.1313,\n",
      "          -5.7400,  -2.4683,  -4.4714,  -3.4117,  -4.4955,  -3.9184, -18.3993,\n",
      "          -4.2819,  -3.5964,  -4.5700,  -3.0546, -19.1501,  -4.8080,  -3.8881,\n",
      "          -4.3752,  -4.7641]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "text representation: tensor([[-1.9149e-01,  4.1578e-02,  1.3939e-01, -1.9426e-01,  2.1661e-01,\n",
      "         -3.4219e-01,  2.9929e-01, -7.2414e-02, -9.3311e-03, -4.6360e-01,\n",
      "          2.4490e-01, -5.3257e-01,  3.4906e-01, -9.1103e-02, -5.9155e-02,\n",
      "         -3.3520e-01,  8.0963e-02,  1.8181e-01, -1.1728e-01, -3.6601e-01,\n",
      "          1.2532e-01, -4.1395e-01, -2.0582e-01, -2.5627e-02,  1.5630e-01,\n",
      "          2.7490e-02,  1.8295e-01,  4.7108e-02,  2.6662e-01, -8.9922e-02,\n",
      "         -4.3843e-01, -1.0229e-01,  1.7174e-01, -3.3785e-01,  1.9728e-01,\n",
      "          2.7953e-01, -3.9825e-01, -2.2568e-01, -3.1980e-02,  1.2343e-01,\n",
      "          5.6846e-02, -1.2437e-02, -4.3383e-01, -5.0335e-01, -2.4746e-01,\n",
      "         -5.9381e-05, -4.5904e-01,  2.7425e-01, -2.5969e-01,  3.5011e-01,\n",
      "          9.8861e-02,  2.2778e-01, -3.4836e-01, -9.2460e-02, -5.6068e-01,\n",
      "         -3.6262e-01,  3.6802e-01, -6.8127e-02,  9.2642e-02,  4.2185e-01,\n",
      "         -2.9398e-01, -3.8559e-01,  3.2054e-01, -4.4533e-01, -3.6169e-02,\n",
      "         -1.3432e-01,  4.1474e-01, -4.8133e-02,  4.7737e-01,  3.2240e-01,\n",
      "          5.4916e-01, -5.2999e-01, -2.7375e-03, -3.2125e-01, -3.9253e-01,\n",
      "          4.9640e-01,  2.5437e-01, -1.3056e-01,  2.8152e-01, -2.5193e-01,\n",
      "         -2.8488e-01, -2.0013e-01, -3.7114e-01, -1.4524e-01,  1.7605e-01,\n",
      "          5.5086e-01,  3.4995e-01, -3.1729e-01,  1.7288e-02, -3.7611e-01,\n",
      "          3.8674e-01,  2.9740e-02,  3.9208e-01,  2.5380e-01,  2.7076e-01,\n",
      "          2.3850e-01,  3.5910e-01,  2.2785e-01,  3.5793e-01,  2.5274e-02],\n",
      "        [-2.8937e-01, -6.1495e-02,  1.7470e-01, -3.1954e-02,  9.4706e-02,\n",
      "         -2.8764e-01,  2.3796e-01, -3.5850e-03,  1.5433e-01, -3.9889e-01,\n",
      "          1.4872e-01, -4.7103e-01,  3.6634e-01,  6.3957e-02, -1.4340e-01,\n",
      "         -3.1044e-01, -5.8238e-02,  2.8474e-01, -1.8238e-01, -3.0692e-01,\n",
      "          1.5789e-01, -4.2833e-01, -1.4413e-01,  1.1567e-01,  3.5313e-02,\n",
      "         -6.5375e-02,  3.0270e-01,  8.4887e-02,  3.6031e-01,  1.9222e-02,\n",
      "         -4.2656e-01, -1.7045e-01,  2.3365e-01, -3.4109e-01,  2.4936e-01,\n",
      "          2.4127e-01, -3.7548e-01, -2.0488e-01,  6.7064e-02,  7.2999e-02,\n",
      "          9.2020e-02,  5.0090e-02, -3.7514e-01, -4.6917e-01, -1.6866e-01,\n",
      "          6.1702e-02, -3.5586e-01,  1.8653e-01, -1.8509e-01,  3.5392e-01,\n",
      "          3.8145e-02,  3.4363e-01, -2.4513e-01, -1.5900e-01, -4.6174e-01,\n",
      "         -4.1895e-01,  3.0089e-01, -5.7952e-02,  2.3316e-01,  4.6922e-01,\n",
      "         -3.5082e-01, -4.2980e-01,  4.1756e-01, -3.5160e-01,  4.6472e-02,\n",
      "         -1.3241e-01,  2.9167e-01,  7.8591e-02,  4.4118e-01,  3.2709e-01,\n",
      "          4.5284e-01, -4.6261e-01, -3.6188e-02, -4.3840e-01, -3.8793e-01,\n",
      "          3.9178e-01,  3.1756e-01, -1.8244e-02,  2.0601e-01, -3.7965e-01,\n",
      "         -1.4721e-01, -2.1413e-01, -3.0068e-01, -1.5904e-01,  4.3302e-02,\n",
      "          5.0500e-01,  2.3686e-01, -3.3354e-01,  1.9014e-02, -4.3299e-01,\n",
      "          3.9791e-01,  2.6786e-02,  2.9829e-01,  2.2066e-01,  2.3526e-01,\n",
      "          3.0324e-01,  3.1349e-01,  2.5996e-01,  3.2071e-01,  1.1859e-01]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "\n",
      "fused: tensor([[-1.9149e-01,  4.1578e-02,  1.3939e-01, -1.9426e-01,  2.1661e-01,\n",
      "         -3.4219e-01,  2.9929e-01, -7.2414e-02, -9.3311e-03, -4.6360e-01,\n",
      "          2.4490e-01, -5.3257e-01,  3.4906e-01, -9.1103e-02, -5.9155e-02,\n",
      "         -3.3520e-01,  8.0963e-02,  1.8181e-01, -1.1728e-01, -3.6601e-01,\n",
      "          1.2532e-01, -4.1395e-01, -2.0582e-01, -2.5627e-02,  1.5630e-01,\n",
      "          2.7490e-02,  1.8295e-01,  4.7108e-02,  2.6662e-01, -8.9922e-02,\n",
      "         -4.3843e-01, -1.0229e-01,  1.7174e-01, -3.3785e-01,  1.9728e-01,\n",
      "          2.7953e-01, -3.9825e-01, -2.2568e-01, -3.1980e-02,  1.2343e-01,\n",
      "          5.6846e-02, -1.2437e-02, -4.3383e-01, -5.0335e-01, -2.4746e-01,\n",
      "         -5.9381e-05, -4.5904e-01,  2.7425e-01, -2.5969e-01,  3.5011e-01,\n",
      "          9.8861e-02,  2.2778e-01, -3.4836e-01, -9.2460e-02, -5.6068e-01,\n",
      "         -3.6262e-01,  3.6802e-01, -6.8127e-02,  9.2642e-02,  4.2185e-01,\n",
      "         -2.9398e-01, -3.8559e-01,  3.2054e-01, -4.4533e-01, -3.6169e-02,\n",
      "         -1.3432e-01,  4.1474e-01, -4.8133e-02,  4.7737e-01,  3.2240e-01,\n",
      "          5.4916e-01, -5.2999e-01, -2.7375e-03, -3.2125e-01, -3.9253e-01,\n",
      "          4.9640e-01,  2.5437e-01, -1.3056e-01,  2.8152e-01, -2.5193e-01,\n",
      "         -2.8488e-01, -2.0013e-01, -3.7114e-01, -1.4524e-01,  1.7605e-01,\n",
      "          5.5086e-01,  3.4995e-01, -3.1729e-01,  1.7288e-02, -3.7611e-01,\n",
      "          3.8674e-01,  2.9740e-02,  3.9208e-01,  2.5380e-01,  2.7076e-01,\n",
      "          2.3850e-01,  3.5910e-01,  2.2785e-01,  3.5793e-01,  2.5274e-02,\n",
      "         -1.7433e+01, -3.7823e+00, -1.8025e+01, -1.7231e+01, -1.6741e+01,\n",
      "         -4.7988e+00, -4.4942e+00, -1.8127e+01, -1.7407e+01, -1.7669e+01,\n",
      "         -1.7284e+01, -1.7286e+01, -1.7482e+01, -3.7412e+00, -1.6990e+01,\n",
      "         -1.7442e+01, -1.6268e+01, -3.6563e+00, -1.7908e+01, -5.4571e+00,\n",
      "         -3.5218e+00, -1.8479e+01, -4.1915e+00, -1.7759e+01, -4.1102e+00,\n",
      "         -1.7461e+01, -1.7174e+01, -1.7192e+01, -4.4624e+00, -1.6643e+01,\n",
      "         -1.7489e+01, -4.1126e+00, -5.0841e+00, -1.6664e+01, -3.6831e+00,\n",
      "         -3.1343e+00, -1.6857e+01, -1.7560e+01, -4.2664e+00, -4.5828e+00,\n",
      "         -1.7182e+01, -4.6842e+00, -2.9977e+00, -3.2286e+00, -1.7640e+01,\n",
      "         -1.6083e+01, -4.1815e+00, -1.6888e+01, -1.6414e+01, -1.7073e+01,\n",
      "         -4.1809e+00, -1.7961e+01, -3.4265e+00, -3.2931e+00, -5.4681e+00,\n",
      "         -1.7925e+01, -3.8898e+00, -1.6989e+01, -4.6905e+00, -4.4860e+00,\n",
      "         -3.9320e+00, -4.3074e+00, -1.7983e+01, -3.7254e+00, -1.7930e+01,\n",
      "         -4.7616e+00, -1.7690e+01, -4.2400e+00, -1.8159e+01, -1.6967e+01,\n",
      "         -4.2171e+00, -1.7527e+01, -3.4701e+00, -3.7656e+00, -1.7482e+01,\n",
      "         -3.4723e+00, -1.8394e+01, -3.7889e+00, -4.5415e+00, -1.8284e+01,\n",
      "         -1.8315e+01, -3.7093e+00, -1.7253e+01, -1.8048e+01, -4.6217e+00,\n",
      "         -3.4212e+00, -3.1531e+00, -4.5736e+00, -4.1450e+00, -4.8706e+00,\n",
      "         -1.8339e+01, -4.0044e+00, -3.8578e+00, -4.7362e+00, -3.8844e+00,\n",
      "         -1.8405e+01, -4.4666e+00, -5.0616e+00, -5.0290e+00, -3.8278e+00],\n",
      "        [-2.8937e-01, -6.1495e-02,  1.7470e-01, -3.1954e-02,  9.4706e-02,\n",
      "         -2.8764e-01,  2.3796e-01, -3.5850e-03,  1.5433e-01, -3.9889e-01,\n",
      "          1.4872e-01, -4.7103e-01,  3.6634e-01,  6.3957e-02, -1.4340e-01,\n",
      "         -3.1044e-01, -5.8238e-02,  2.8474e-01, -1.8238e-01, -3.0692e-01,\n",
      "          1.5789e-01, -4.2833e-01, -1.4413e-01,  1.1567e-01,  3.5313e-02,\n",
      "         -6.5375e-02,  3.0270e-01,  8.4887e-02,  3.6031e-01,  1.9222e-02,\n",
      "         -4.2656e-01, -1.7045e-01,  2.3365e-01, -3.4109e-01,  2.4936e-01,\n",
      "          2.4127e-01, -3.7548e-01, -2.0488e-01,  6.7064e-02,  7.2999e-02,\n",
      "          9.2020e-02,  5.0090e-02, -3.7514e-01, -4.6917e-01, -1.6866e-01,\n",
      "          6.1702e-02, -3.5586e-01,  1.8653e-01, -1.8509e-01,  3.5392e-01,\n",
      "          3.8145e-02,  3.4363e-01, -2.4513e-01, -1.5900e-01, -4.6174e-01,\n",
      "         -4.1895e-01,  3.0089e-01, -5.7952e-02,  2.3316e-01,  4.6922e-01,\n",
      "         -3.5082e-01, -4.2980e-01,  4.1756e-01, -3.5160e-01,  4.6472e-02,\n",
      "         -1.3241e-01,  2.9167e-01,  7.8591e-02,  4.4118e-01,  3.2709e-01,\n",
      "          4.5284e-01, -4.6261e-01, -3.6188e-02, -4.3840e-01, -3.8793e-01,\n",
      "          3.9178e-01,  3.1756e-01, -1.8244e-02,  2.0601e-01, -3.7965e-01,\n",
      "         -1.4721e-01, -2.1413e-01, -3.0068e-01, -1.5904e-01,  4.3302e-02,\n",
      "          5.0500e-01,  2.3686e-01, -3.3354e-01,  1.9014e-02, -4.3299e-01,\n",
      "          3.9791e-01,  2.6786e-02,  2.9829e-01,  2.2066e-01,  2.3526e-01,\n",
      "          3.0324e-01,  3.1349e-01,  2.5996e-01,  3.2071e-01,  1.1859e-01,\n",
      "         -1.7294e+01, -3.9461e+00, -1.6710e+01, -1.7727e+01, -1.7604e+01,\n",
      "         -3.9542e+00, -4.0016e+00, -1.7743e+01, -1.7230e+01, -1.7480e+01,\n",
      "         -1.8735e+01, -1.7566e+01, -1.8029e+01, -3.8010e+00, -1.7864e+01,\n",
      "         -1.7734e+01, -1.6850e+01, -3.2725e+00, -1.7249e+01, -4.4215e+00,\n",
      "         -5.2942e+00, -1.7690e+01, -3.8863e+00, -1.8300e+01, -4.0054e+00,\n",
      "         -1.7080e+01, -1.7148e+01, -1.7299e+01, -5.2400e+00, -1.5321e+01,\n",
      "         -1.7080e+01, -4.2095e+00, -4.4163e+00, -1.6434e+01, -3.9776e+00,\n",
      "         -3.3407e+00, -1.6407e+01, -1.7728e+01, -3.7422e+00, -4.7391e+00,\n",
      "         -1.7325e+01, -4.2130e+00, -3.4011e+00, -3.7878e+00, -1.7683e+01,\n",
      "         -1.6182e+01, -3.8344e+00, -1.7040e+01, -1.6481e+01, -1.7781e+01,\n",
      "         -3.6535e+00, -1.7645e+01, -4.0866e+00, -3.7601e+00, -5.3311e+00,\n",
      "         -1.7579e+01, -4.1109e+00, -1.6876e+01, -4.1382e+00, -4.7599e+00,\n",
      "         -3.1937e+00, -5.0059e+00, -1.7284e+01, -4.7423e+00, -1.8502e+01,\n",
      "         -5.2747e+00, -1.7987e+01, -3.4170e+00, -1.9167e+01, -1.7140e+01,\n",
      "         -3.8418e+00, -1.8151e+01, -4.2615e+00, -4.5730e+00, -1.8302e+01,\n",
      "         -4.5811e+00, -1.7834e+01, -4.2390e+00, -4.2131e+00, -1.8765e+01,\n",
      "         -1.9580e+01, -4.3739e+00, -1.6762e+01, -1.8131e+01, -5.7400e+00,\n",
      "         -2.4683e+00, -4.4714e+00, -3.4117e+00, -4.4955e+00, -3.9184e+00,\n",
      "         -1.8399e+01, -4.2819e+00, -3.5964e+00, -4.5700e+00, -3.0546e+00,\n",
      "         -1.9150e+01, -4.8080e+00, -3.8881e+00, -4.3752e+00, -4.7641e+00]],\n",
      "       grad_fn=<CatBackward>)\n",
      "y_hat: tensor([[ 28.1080, -29.6945],\n",
      "        [ 28.5386, -29.5849]], grad_fn=<AddmmBackward>)\n",
      "pred: tensor([0, 0])\n",
      "train loss 0.000, val loss 0.000, val accuracy 1.000\n",
      "CPU times: user 3.38 s, sys: 163 ms, total: 3.54 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(model=model, epochs=2, lr=0.01, train_loader=train_loader, train_seq_loader=train_seq_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.Tensor(([[-4.2521, -4.2464, -4.4741, -4.5547, -4.5478, -5.5457, -5.3049, -5.1204,\n",
    "         -5.1457, -5.2056, -4.5313, -5.0253, -4.7385, -4.7661, -4.5265, -4.2586,\n",
    "         -3.3594, -4.3817, -4.1012, -5.8242, -5.5435, -5.0205, -5.0595, -4.6622,\n",
    "         -4.5196, -4.2702, -4.5995, -4.6876, -5.2176, -3.2149, -4.6365, -4.9898,\n",
    "         -5.5991, -4.2091, -4.7610, -4.1638, -3.8122, -4.7662, -5.0462, -4.9526,\n",
    "         -4.7008, -4.5671, -4.3898, -4.1583, -4.2191, -3.2409, -4.4813, -4.4752,\n",
    "         -2.9030, -4.5563, -4.8537, -4.8357, -4.2699, -4.6099, -5.8208, -5.1968,\n",
    "         -4.3736, -4.7389, -5.1744, -4.9667, -3.9274, -5.3632, -4.8872, -5.0379,\n",
    "         -5.2167, -5.8661, -4.7592, -5.0030, -5.5042, -4.4636, -4.7795, -5.1121,\n",
    "         -4.3879, -4.8093, -5.2627, -5.0186, -5.2898, -4.6608, -4.6598, -5.9072,\n",
    "         -5.5910, -4.7094, -4.7134, -5.2310, -5.1905, -4.3843, -4.2540, -4.8409,\n",
    "         -4.6072, -4.9843, -5.3077, -4.9965, -4.7092, -5.1058, -4.5060, -6.0548,\n",
    "         -5.5167, -5.2616, -5.4040, -5.0175]])\n",
    "               \n",
    "b=torch.Tensor(([[-11.9913,  -3.7826, -12.5833, -11.7889, -11.2992,  -4.7991,  -4.4945,\n",
    "         -12.6855, -11.9649, -12.2276, -11.8422, -11.8447, -12.0405,  -3.7416,\n",
    "         -11.5485, -11.9999, -10.8261,  -3.6566, -12.4659,  -5.4574,  -3.5221,\n",
    "         -13.0376,  -4.1919, -12.3176,  -4.1105, -12.0193, -11.7328, -11.7507,\n",
    "          -4.4628, -11.2013, -12.0474,  -4.1130,  -5.0844, -11.2223,  -3.6835,\n",
    "          -3.1347, -11.4154, -12.1186,  -4.2668,  -4.5831, -11.7406,  -4.6845,\n",
    "          -2.9980,  -3.2289, -12.1989, -10.6418,  -4.1819, -11.4468, -10.9723,\n",
    "         -11.6317,  -4.1813, -12.5192,  -3.4268,  -3.2935,  -5.4684, -12.4832,\n",
    "          -3.8902, -11.5476,  -4.6908,  -4.4863,  -3.9324,  -4.3077, -12.5412,\n",
    "          -3.7257, -12.4882,  -4.7619, -12.2484,  -4.2403, -12.7177, -11.5256,\n",
    "          -4.2174, -12.0858,  -3.4705,  -3.7659, -12.0408,  -3.4726, -12.9526,\n",
    "          -3.7892,  -4.5419, -12.8421, -12.8729,  -3.7096, -11.8118, -12.6065,\n",
    "          -4.6220,  -3.4215,  -3.1535,  -4.5739,  -4.1453,  -4.8709, -12.8969,\n",
    "          -4.0048,  -3.8581,  -4.7366,  -3.8848, -12.9636,  -4.4669,  -5.0619,\n",
    "          -5.0294,  -3.8282],\n",
    "        [-11.8447,  -3.9464, -11.2609, -12.2781, -12.1543,  -3.9545,  -4.0019,\n",
    "         -12.2932, -11.7808, -12.0304, -13.2854, -12.1163, -12.5795,  -3.8014,\n",
    "         -12.4147, -12.2848, -11.4008,  -3.2728, -11.7993,  -4.4218,  -5.2945,\n",
    "         -12.2411,  -3.8866, -12.8508,  -4.0057, -11.6302, -11.6989, -11.8493,\n",
    "          -5.2403,  -9.8713, -11.6305,  -4.2098,  -4.4167, -10.9850,  -3.9780,\n",
    "          -3.3411, -10.9573, -12.2791,  -3.7425,  -4.7395, -11.8754,  -4.2133,\n",
    "          -3.4015,  -3.7881, -12.2334, -10.7329,  -3.8347, -11.5902, -11.0319,\n",
    "         -12.3321,  -3.6539, -12.1957,  -4.0869,  -3.7605,  -5.3315, -12.1294,\n",
    "          -4.1113, -11.4262,  -4.1386,  -4.7603,  -3.1940,  -5.0062, -11.8343,\n",
    "          -4.7427, -13.0524,  -5.2751, -12.5379,  -3.4173, -13.7172, -11.6907,\n",
    "          -3.8422, -12.7018,  -4.2619,  -4.5733, -12.8526,  -4.5814, -12.3846,\n",
    "          -4.2394,  -4.2135, -13.3160, -14.1304,  -4.3743, -11.3125, -12.6819,\n",
    "          -5.7403,  -2.4686,  -4.4718,  -3.4121,  -4.4958,  -3.9187, -12.9499,\n",
    "          -4.2822,  -3.5968,  -4.5703,  -3.0550, -13.7008,  -4.8083,  -3.8884,\n",
    "          -4.3756,  -4.7645]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_seq_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor([[[[-2.0323, -2.0323, -2.0323,  ..., -2.0152, -2.0152, -2.0323],\n",
      "          [-2.0323, -2.0323, -2.0323,  ..., -1.9467, -1.9638, -2.0323],\n",
      "          [-2.0323, -2.0323, -2.0323,  ..., -1.9124, -1.9124, -1.9980],\n",
      "          ...,\n",
      "          [-1.5870, -1.5870, -1.5870,  ..., -1.3644, -1.3473, -1.3473],\n",
      "          [-1.5699, -1.5699, -1.5699,  ..., -1.3644, -1.3644, -1.3815],\n",
      "          [-1.5357, -1.5357, -1.5357,  ..., -1.3644, -1.3815, -1.4158]],\n",
      "\n",
      "         [[-0.6877, -0.6877, -0.6877,  ..., -0.7052, -0.6877, -0.6702],\n",
      "          [-0.6877, -0.6877, -0.6877,  ..., -0.6702, -0.6702, -0.6702],\n",
      "          [-0.6877, -0.6877, -0.6877,  ..., -0.7227, -0.6527, -0.6352],\n",
      "          ...,\n",
      "          [-0.7402, -0.7402, -0.7402,  ..., -0.3550, -0.3375, -0.3375],\n",
      "          [-0.7227, -0.7227, -0.7227,  ..., -0.3550, -0.3550, -0.3725],\n",
      "          [-0.6877, -0.6877, -0.6877,  ..., -0.3550, -0.3725, -0.4076]],\n",
      "\n",
      "         [[ 0.8274,  0.8274,  0.8274,  ...,  0.7054,  0.7228,  0.7576],\n",
      "          [ 0.8274,  0.8274,  0.8274,  ...,  0.6705,  0.6879,  0.7576],\n",
      "          [ 0.8274,  0.8274,  0.8274,  ...,  0.5659,  0.6531,  0.7925],\n",
      "          ...,\n",
      "          [ 0.2696,  0.2696,  0.2696,  ...,  0.6879,  0.7054,  0.7054],\n",
      "          [ 0.2871,  0.2871,  0.2871,  ...,  0.6879,  0.6879,  0.6705],\n",
      "          [ 0.3219,  0.3219,  0.3219,  ...,  0.6879,  0.6705,  0.6356]]]])\n",
      "x2 tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      "img representation: tensor([[-4.0983, -5.2199, -4.3792, -4.2309, -6.0392, -4.8014, -4.3715, -6.4910,\n",
      "         -5.2845, -4.2545, -5.0993, -5.1253, -4.4658, -4.7478, -4.6579, -4.8724,\n",
      "         -5.4594, -4.2422, -4.4594, -5.5135, -3.6493, -5.6196, -4.9082, -5.1369,\n",
      "         -6.3514, -5.2456, -5.2697, -5.2253, -4.7091, -5.7350, -5.5734, -5.1303,\n",
      "         -4.2368, -5.0091, -5.3515, -3.9397, -5.0215, -4.4803, -4.7826, -4.7912,\n",
      "         -4.1746, -4.2604, -6.2648, -3.3710, -4.7571, -4.9140, -4.9384, -4.6549,\n",
      "         -4.9208, -3.5884, -5.6102, -5.4464, -4.8741, -5.4224, -4.9623, -5.4987,\n",
      "         -4.0284, -4.9247, -6.2442, -4.6860, -4.2235, -3.9102, -4.2861, -5.6787,\n",
      "         -4.8862, -4.7575, -3.8320, -4.7272, -4.5979, -4.4000, -4.9106, -4.0333,\n",
      "         -5.3516, -4.4798, -5.5390, -4.9156, -4.7305, -3.3986, -4.7312, -4.4670,\n",
      "         -4.9871, -4.4925, -5.4017, -4.8602, -4.5116, -5.4511, -4.0252, -3.0386,\n",
      "         -4.5819, -4.2542, -5.0201, -4.8838, -4.1832, -4.9835, -4.6042, -4.6242,\n",
      "         -4.6148, -4.5404, -5.5486, -4.8036]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "text representation: tensor([[ 0.1639, -0.3111, -0.4007,  0.5131, -0.2668, -0.3702, -0.4471, -0.0204,\n",
      "          0.1470, -0.3462, -0.0126, -0.2149, -0.2513,  0.1541,  0.3976,  0.1780,\n",
      "          0.3718,  0.4206, -0.1505, -0.2242,  0.2860,  0.1610, -0.1429, -0.3934,\n",
      "          0.3989,  0.0188, -0.0967,  0.3527, -0.3924,  0.3418, -0.4307, -0.0292,\n",
      "          0.3275,  0.0539,  0.3745, -0.2629,  0.3123, -0.3041, -0.4015, -0.0666,\n",
      "          0.0118,  0.3639, -0.3430,  0.2979, -0.0953,  0.3415, -0.0453,  0.1580,\n",
      "          0.1798, -0.1467, -0.0181,  0.2003,  0.2404,  0.0718,  0.1840,  0.1125,\n",
      "          0.4157,  0.0774,  0.3057, -0.0996,  0.0024, -0.2145,  0.4077, -0.1666,\n",
      "         -0.3298,  0.3600, -0.3502, -0.0478, -0.3832,  0.1605,  0.3129,  0.3739,\n",
      "         -0.2646, -0.1075, -0.3411,  0.1096, -0.3657, -0.2992, -0.1551,  0.3694,\n",
      "         -0.0734, -0.0488, -0.0988,  0.2925, -0.2129, -0.1392,  0.3759,  0.3700,\n",
      "         -0.1510,  0.3445, -0.3728,  0.2721, -0.2267,  0.1782, -0.1369,  0.0494,\n",
      "          0.2306, -0.3084,  0.1122,  0.0037]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "fused: tensor([[ 1.6391e-01, -3.1114e-01, -4.0067e-01,  5.1315e-01, -2.6678e-01,\n",
      "         -3.7022e-01, -4.4706e-01, -2.0450e-02,  1.4698e-01, -3.4616e-01,\n",
      "         -1.2638e-02, -2.1490e-01, -2.5128e-01,  1.5412e-01,  3.9764e-01,\n",
      "          1.7797e-01,  3.7181e-01,  4.2064e-01, -1.5051e-01, -2.2422e-01,\n",
      "          2.8605e-01,  1.6096e-01, -1.4288e-01, -3.9342e-01,  3.9894e-01,\n",
      "          1.8798e-02, -9.6714e-02,  3.5273e-01, -3.9239e-01,  3.4185e-01,\n",
      "         -4.3066e-01, -2.9174e-02,  3.2752e-01,  5.3901e-02,  3.7453e-01,\n",
      "         -2.6292e-01,  3.1229e-01, -3.0405e-01, -4.0147e-01, -6.6642e-02,\n",
      "          1.1818e-02,  3.6392e-01, -3.4299e-01,  2.9789e-01, -9.5260e-02,\n",
      "          3.4150e-01, -4.5275e-02,  1.5798e-01,  1.7981e-01, -1.4675e-01,\n",
      "         -1.8102e-02,  2.0029e-01,  2.4037e-01,  7.1760e-02,  1.8399e-01,\n",
      "          1.1246e-01,  4.1575e-01,  7.7428e-02,  3.0567e-01, -9.9643e-02,\n",
      "          2.3701e-03, -2.1455e-01,  4.0773e-01, -1.6655e-01, -3.2981e-01,\n",
      "          3.6000e-01, -3.5018e-01, -4.7760e-02, -3.8320e-01,  1.6053e-01,\n",
      "          3.1292e-01,  3.7389e-01, -2.6461e-01, -1.0748e-01, -3.4108e-01,\n",
      "          1.0965e-01, -3.6568e-01, -2.9925e-01, -1.5510e-01,  3.6936e-01,\n",
      "         -7.3433e-02, -4.8833e-02, -9.8835e-02,  2.9248e-01, -2.1294e-01,\n",
      "         -1.3916e-01,  3.7594e-01,  3.7003e-01, -1.5102e-01,  3.4450e-01,\n",
      "         -3.7279e-01,  2.7210e-01, -2.2668e-01,  1.7819e-01, -1.3690e-01,\n",
      "          4.9450e-02,  2.3057e-01, -3.0840e-01,  1.1219e-01,  3.7428e-03,\n",
      "         -4.0983e+00, -5.2199e+00, -4.3792e+00, -4.2309e+00, -6.0392e+00,\n",
      "         -4.8014e+00, -4.3715e+00, -6.4910e+00, -5.2845e+00, -4.2545e+00,\n",
      "         -5.0993e+00, -5.1253e+00, -4.4658e+00, -4.7478e+00, -4.6579e+00,\n",
      "         -4.8724e+00, -5.4594e+00, -4.2422e+00, -4.4594e+00, -5.5135e+00,\n",
      "         -3.6493e+00, -5.6196e+00, -4.9082e+00, -5.1369e+00, -6.3514e+00,\n",
      "         -5.2456e+00, -5.2697e+00, -5.2253e+00, -4.7091e+00, -5.7350e+00,\n",
      "         -5.5734e+00, -5.1303e+00, -4.2368e+00, -5.0091e+00, -5.3515e+00,\n",
      "         -3.9397e+00, -5.0215e+00, -4.4803e+00, -4.7826e+00, -4.7912e+00,\n",
      "         -4.1746e+00, -4.2604e+00, -6.2648e+00, -3.3710e+00, -4.7571e+00,\n",
      "         -4.9140e+00, -4.9384e+00, -4.6549e+00, -4.9208e+00, -3.5884e+00,\n",
      "         -5.6102e+00, -5.4464e+00, -4.8741e+00, -5.4224e+00, -4.9623e+00,\n",
      "         -5.4987e+00, -4.0284e+00, -4.9247e+00, -6.2442e+00, -4.6860e+00,\n",
      "         -4.2235e+00, -3.9102e+00, -4.2861e+00, -5.6787e+00, -4.8862e+00,\n",
      "         -4.7575e+00, -3.8320e+00, -4.7272e+00, -4.5979e+00, -4.4000e+00,\n",
      "         -4.9106e+00, -4.0333e+00, -5.3516e+00, -4.4798e+00, -5.5390e+00,\n",
      "         -4.9156e+00, -4.7305e+00, -3.3986e+00, -4.7312e+00, -4.4670e+00,\n",
      "         -4.9871e+00, -4.4925e+00, -5.4017e+00, -4.8602e+00, -4.5116e+00,\n",
      "         -5.4511e+00, -4.0252e+00, -3.0386e+00, -4.5819e+00, -4.2542e+00,\n",
      "         -5.0201e+00, -4.8838e+00, -4.1832e+00, -4.9835e+00, -4.6042e+00,\n",
      "         -4.6242e+00, -4.6148e+00, -4.5404e+00, -5.5486e+00, -4.8036e+00]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(zip(train_loader, train_seq_loader)):\n",
    "        #for data in zip(validation_loader, valid_seq_loader): \n",
    "    img_vectors, text_sequences, y_train = data[0][0], data[1], data[0][1]      \n",
    "#             x = x.long()\n",
    "#             y = y.long()\n",
    "    #optimizer.zero_grad()\n",
    "    y_pred = model(img_vectors, text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1595852529951,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
